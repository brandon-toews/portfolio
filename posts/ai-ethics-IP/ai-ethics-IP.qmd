---
title: "Artificial Intelligence and Intellectual Property"
format:
  html: default
  pdf: default
author: "Brandon Toews"
badges: true
categories:
- AI / ML
date: "2023-12-21"
description: This paper critically examines the ethical implications of AI and intellectual property, focusing on the intersection of legal frameworks and psychological factors.
toc: true
number-sections: true
image: post-pic.jpg
twitter-card: true
card-style: summary
crossref:
  fig-title: '**Figure**'
  fig-labels: arabic
  title-delim: "**.**"
---

\

![](post-pic.jpg)

# Exploring the Ethical Implications of Artificial Intelligence and Intellectual Property: A Legal and Psychological Analysis {.unnumbered .unlisted}

# Abstract {.unnumbered}

As artificial intelligence (AI) continues to advance, the ethical dimensions of its impact on intellectual property (IP) become increasingly critical. This paper critically examines the ethical implications of AI and IP, focusing on the intersection of legal frameworks and psychological factors. The primary research question addresses the potential ethical impacts of AI in IP, dissecting both legal and psychological dimensions separately and within organizational contexts. The methodology integrates in-depth exploration of legal dimensions using established frameworks and precedents, complemented by an extensive review of relevant psychological literature. The synthesis of these dimensions reveals the complexity introduced by AI, uncovering several possible negative ethical impacts. The legal landscape, characterized by soft law measures and a lag in regulatory development, may amplify psychological factors influencing unethical behavior. The paper explores how anticipated guilt, social acceptability, and psychological distance contribute to unethical behavior, especially in the context of IP theft facilitated by AI. Organizational psychological factors, such as Psychological Contract Theory and future self-continuity, are also examined, shedding light on potential avenues for unethical use of AI in IP within organizational settings. The conclusion emphasizes the need for regulatory frameworks aligned with ethical principles to address psychological factors and minimize the risks associated with AI in IP. While acknowledging the potential for AI to enhance IP protection, the paper underscores the importance of mitigating risks associated with its dual-use nature, emphasizing the role of societal and regulatory tools in fostering an ethical AI environment.

# Introduction

As AI advances it becomes increasingly more powerful and therefore more capable of dealing harm. The ever-looming question remains, how will those who use and develop this technology wield it? IP is near and dear to our hearts as a society, and we go to great lengths to establish and protect it. Being the powerful tool that it is, it is important that we analyze what ethical impacts AI could have on IP. This paper aims to critically examine the ethical implications of AI in IP, focusing on the intersection of legal frameworks and psychological factors. The primary research question guiding this investigation is what the potential ethical impacts of AI in IP are. We will discuss the legal landscape of AI usage and development and psychological factors underpinning unethical behavior in individuals separately and within an organization. An examination of these will demonstrate that the added layer of complexity by the introduction and use of AI does present a number of possible negative ethical impacts.

The methodology employed in this study involves an in-depth exploration of legal dimensions, drawing on established frameworks and precedents. The psychological factors are examined through an extensive review of relevant literature, ensuring a thorough analysis. This dual methodology is particularly pertinent as it enables the identification of potential conflicts, intersections, and gaps between legal and psychological considerations. The legal analysis establishes the framework within which ethical behavior is expected, while insights from psychology elucidate the factors that may influence adherence or deviation from these ethical norms. The synergy between these dimensions contributes a unique and valuable perspective to the ongoing discourse on AI ethics.

# Literature Review

## Legal landscape

It can be argued that there is a growing emphasis on ethical AI development, with organizations and researchers actively working to establish ethical principles and guidelines ([Carrillo, M. R., 2020, p.6](#references)). While there has been progress made in ethical AI development ([Nourbakhsh, I. R., 2021, p.1](#references)), potential negative ethical impacts still exist. Focusing solely on ethical principles may not be sufficient to prevent unethical behavior. A distinction between law and ethics must be established to carefully consider the ethical impacts raised in this paper. Laws are created to enforce what society agrees on as ethically acceptable and to hold individuals accountable for those ethical standards. Widespread confusion between legal and ethical principles specifically in AI is used to develop ethical principles to the exclusion of laws, reasoning that they are interchangeable ([Carrillo, M. R., 2020, p.6](#references)). On the surface, it may seem favorable to focus more on establishing ethical principles, but this may be counterproductive to ensuring ethical behavior.

The current legal landscape for AI development may exacerbate the psychological factors underpinning unethical behavior in this space. In recent years, soft law measures have been taken supporting ethical principles over hard regulation. Most notably, soft law, an international instrument containing statements of expected behavior ([Yan, M., 2019, p.50](#references)), lacks enforceability and accountability in that there is often no development of institutional frameworks or clear assignment of responsibility ([Delacroix, S. and Wagner, B., 2021, p.3](#references)). Concepts of cost, risk and social acceptability exert considerably influence over whether an individual will engage in unethical behavior. In the absence of regulation, perceptions of cost and risk are minimized and, in some cases, even contribute to increased social acceptance of unethical behavior ([Mills, P. and Groening, C., 2021, pp.378-380](#references)). Given that it can be difficult to establish IP alone, with the addition of AI bringing with it its current regulatory state may obscure the costs and risks associated with IP theft even further. Lack of regulation in AI development may also fuel social acceptance to abuse AI in regard to IP, as is the case in password sharing with Netflix ([Mills, P. and Groening, C., 2021, pp.378](#references)).

Critics might argue that legal frameworks will eventually catch up with AI advancements, closing regulatory gaps and minimizing the risks of unethical behavior. While legal frameworks do have the potential to evolve, the challenge remains in catching up and keeping pace with rapidly advancing AI technologies. Waiting for legal frameworks to catch up might allow a window for unethical practices to proliferate.

In addition, psychological factors contribute to whether a person will commit unethical behaviors. Concepts such as anticipated guilt, social acceptability, indirect action, psychological distance and cost/rewards can be used to explain or even predict the likelihood of unethical behavior ([Mills, P. and Groening, C., 2021, pp.378-380](#references), [Gratch, J. and Fast, N. J., 2022, pp.2-4](#references), [Reardon, J. et al., 2019, pp.511,514](#references)). These concepts will be elaborated on to further tease out the ethical impact that AI may have on IP.

## Psychological factors that contribute to unethical behavior

[Reardon, J. et al. (2019, p.522)](#references) has demonstrated that a consumer's ethical perceptions about downloading pirated music had the highest direct impact on whether they participated in such activities. Namely, if a consumer felt strongly that downloading illegal music was ethically wrong then they were far less likely to do it. This beautifully illustrates how having a strong ethical code can have a massive impact in preventing unethical behavior. [Ellis, L. M. (2022, pp.9,10,12)](#references) explains that idea theft is looked upon more harshly than money theft because the behavior is most often attributed to negative personality characteristics such as self-interest and inauthenticity. As a result, idea thieves suffer severe interpersonal consequences thereby proving idea theft is regarded as a highly unethical behavior ([Ellis, L. M., 2022, p.12](#references)). There are limitations in linking [Ellis, L. M. (2022)](#references) studies on idea theft specifically with IP theft as there are nuanced differences between the two. However, as the two bear marked similarities in core concepts such as financial gain and authenticity it is reasonable to conclude both are viewed similarly as highly unethical behaviors by society in general.

Seeing that IP theft is considered as highly unethical and ethical perceptions have the highest direct impact in preventing unethical behavior one could conclude that pursuing the development of ethical principles to the exclusion of laws may be the most effective approach. However, [González-Esteban y Patrici Calvo, E. (2022, p.1)](#references) reveals that there exists an increase in professional malpractice including plagiarism, illicit appropriation of ideas, concepts, and results and improper or fraudulent use of information. While IP theft is not specifically listed as increasing by [González-Esteban y Patrici Calvo, E. (2022, p.1)](#references) the actions that are listed comprise some if not all aspects of IP theft. How is it that actions which contribute to IP theft remain prevalent amidst strong ethical perceptions against them are maintained at large? In this author's opinion, the answer to that question highlights the potential ethical impact that AI introduces to the subject of IP.

The apparent contradiction between what should theoretically prevent IP theft and the reality of the situation can, in part, be explained by the psychological factors we touched on earlier. Anticipated guilt, arising from a consideration of violating one's own standards, produces powerful motivation to act within the bounds of one's ethical perceptions ([Mills, P. and Groening, C., 2021, pp.378-380](#references), [Reardon, J. et al., 2019, pp.511,514](#references)). However, when there exists a social consensus that a given behavior is ethically acceptable evidenced by the fact that many individuals engage in the behavior this constitutes social acceptability. Social acceptability exerts a potent moderating effect of anticipated guilt such that as social acceptability of an unethical behavior increases so does engagement in said behavior ([Mills, P. and Groening, C., 2021, pp.378-380](#references)). There exist strong personal motivations, namely anticipated guilt, to avoid engaging in IP theft. However, the social acceptability of core behaviors involved in IP theft has likely caused many to defer their ethical reservations on the matter.

AI may strengthen other psychological factors that could influence the social acceptability of IP theft. [Gratch, J. and Fast, N. J. (2022, pp.2)](#references) explain that indirect action, when one party acts on another through an agent, increases likelihood of unethical behavior. An attractive feature of AI is its ability to process amounts of data that are impossible for a human to absorb and extract valuable insights from that data. Therefore, it is likely that humans will use AI to sift through data that may, without their knowledge, contain IP. The model may then present insights that encroach on someone else's IP but by the process abstracts the ideas from the owner of the property. This presents a potential situation whereby an individual could inadvertently steal someone else's IP. Or the psychological distance afforded through the indirect action of using an AI model may reduce the perceived intensity of the negative consequences ([Gratch, J. and Fast, N. J. 2022, p.2](#references)). In either case, these lower perceptions of the potential cost involved in the action increase the likelihood of IP theft. The increased likelihood of using AI to steal IP could then result in an increase in cases resulting in an even greater social acceptance of this unethical behavior.

## Organizational psychological factors

The discussion up until this point has been formulated around the individual use of AI in IP. However, other psychological factors explaining unethical behavior emerge when considering the social and environmental dynamics that accompany life in an organization. The prevalence of corporate scandals indicates a pervasiveness of unethical behavior that routinely transpires within organizations ([Griep, Y. et al., 2023, p.1](#references)). While AI technology is becoming increasingly more accessible to individuals, the development and usage of these is still more accessible to organizations that possess the resources to engage them. It is important to ponder AI usage within the context of an organizational environment with the objectives that accompany it and how this could further elucidate the ethical impacts it may have on IP.

Psychological Contract Theory posits that an employee has a mental model of the exchange agreement between him/herself and the organization. This psychological contract is what they believe their organization is obligated to provide them with in return for their contributions. A perceived breach in this contract increases the likelihood that the employee will engage in unethical behavior that harms the company. However, if the contract is perceived as fulfilled then the employee is more likely to engage in unethical pro-organizational behavior as they feel obligate to reciprocate beneficial treatment. Unethical pro-organizational behaviors are unethical acts that employees engage in with a desire to benefit their organization. Even though these acts routinely damage organizations, the employees who perpetrate them have the intention of helping ([Griep, Y. et al., 2023, pp.2,12,13](#references)).

Organizations with the resources to develop and employ AI technologies often deliver competitive wages and benefits to their employees. This increases the likelihood that their employees would be more inclined towards unethical pro-organizational behavior resulting in AI abuse at the expense of IP. Feelings of obligation to reciprocate beneficial treatment may move employees to use AI to steal IP even when the organization does not condone it. Employees that discover previously unknown IP theft in their models may be inclined to lie about and/or cover up the training dataset. These coupled with the speed with which an AI model can process data could facilitate IP theft on a mass scale.

Future self-continuity refers to how well a person identifies with themself in the future and if they can image how they might feel. If their future self feels like a stranger to them then they are more likely to act in an unethical way because they do not have a good sense of how they will feel in the future ([Hershfield, H. E., Cohen, T. R. and Thompson, L., 2012, p.300](#references)). [Hershfield, H. E., Cohen, T. R. and Thompson, L. (2012, pp.307-308)](#references) were able to shift a person to think more in terms of the future in general rather than future self and by doing so increased a propensity to think more about immediate short-term gains and thereby increase likelihood of engaging in unethical behavior. Many organizations channel employees focus on quarterly earnings and shareholder meetings where the goal is increased profit from last quarter. This consistent and pressurized training of focus on short-term outcomes may successfully shift employee thinking away from a healthier future self-continuity thereby raising likelihood of them engaging in unethical behavior. With a lower future self-continuity, a person may feel more inclined to seize a competitive edge by using AI to steal IP.

Any one of these two organizational factors on their own increase likelihood of unethical behavior but in combination with each other creates powerful conditions to elicit unethical use of AI. Unethical use of AI, being able to bestow great financial rewards, may be all too tempting for someone who feels an obligation to reciprocate beneficial treatment. Especially when an individual's focus is being constantly aligned with quarterly earnings, shifting thoughts from ethically fortifying thought patterns of future self-continuity. If we include the current legal landscape of AI use and development, with its lack of regulatory boundaries, along with psychological distance afforded by AI technologies, a deadly cocktail emerges. A potent cocktail that can easily intoxicate individuals towards unethical use and further adding to it a rise in social acceptability. As illustrated, these issues can stack up on each other to add more weight towards tipping the scales in favor of unethical behavior.

# Conclusion

Some may contend that AI technologies can be employed to enhance IP protection, providing better tools for monitoring and preventing IP theft. There is significant potential for AI to contribute to IP protection but that does not discount the dual-use nature of technology. AI's capabilities can be exploited for both positive and negative purposes, and the focus should be on minimizing the risks associated with unethical use. Further research into developing regulatory frameworks in lockstep with ethical principles to specifically address the psychological factors underpinning unethical behavior may produce more favorable outcomes in the future. In this author's opinion, if we work towards creating a psychological environment that favors ethical uses of AI using societal and regulatory tools, we will minimize negative and maximize positive impacts of AI in IP.

Examining the ethical impact of AI on IP is a complex endeavor. Of the many layers to consider in addressing this subject, an examination of the psychology behind ethical/unethical behavior, inside and outside organizations, alongside the current capabilities and regulatory state of AI is needed. After considering these, we see that there are conditions that foster an environment conducive to negative ethical impacts. Although there are strong trends towards developing robust ethical principles in AI development, some negative ethical impacts are sure to in sue. It may be that the psychological effects of using AI technologies will lead to an increase of unethical use of IP. Or the capabilities of AI may enable IP theft on a greater scale thus increasing cases. It remains unclear whether there will be an increase in IP crime with the integration of AI technologies. Nevertheless, AI constitutes a potent tool that introduces a heightened level of complexity to the understanding of factors influencing unethical behavior. While we endeavor to adjust to this addition of complexity in the matter, we are likely to see new and unforeseeable ethical dynamics emerge that call us to readjust accordingly.

# References {#references .unnumbered}

Carrillo, M. R. (2020) "Artificial Intelligence: From Ethics to Law," Telecommunications Policy, 44(6), pp. 1--1. doi: 10.1016/j.telpol.2020.101937.

Delacroix, S. and Wagner, B. (2021) "Constructing a Mutually Supportive Interface between Ethics and Regulation," Computer Law & Security Review: The International Journal of Technology Law and Practice, 40. doi: 10.1016/j.clsr.2020.105520.

Ellis, L. M. (2022) "The Interpersonal Consequences of Stealing Ideas: Worse Character Judgments and Less Co-Worker Support for an Idea (vs. Money) Thief," Organizational Behavior and Human Decision Processes, 171. doi: 10.1016/j.obhdp.2022.104165.

González-Esteban y Patrici Calvo, E. (2022) "Ethically Governing Artificial Intelligence in the Field of Scientific Research and Innovation," Heliyon, 8(2). doi: 10.1016/j.heliyon.2022.e08946.

Gratch, J. and Fast, N. J. (2022) "The Power to Harm: Ai Assistants Pave the Way to Unethical Behavior," Current Opinion in Psychology, 47. doi: 10.1016/j.copsyc.2022.101382.

Griep, Y. et al. (2023) "You Scratch My Back, I'll Scratch Yours: Unethical Pro-Organizational Behavior and Deviance in Response to Different Psychological Contract States," Journal of business research, 156.

Hershfield, H. E., Cohen, T. R. and Thompson, L. (2012) "Short Horizons and Tempting Situations: Lack of Continuity to Our Future Selves Leads to Unethical Decision Making and Behavior," Organizational Behavior and Human Decision Processes, 117(2), pp. 298--310. doi: 10.1016/j.obhdp.2011.11.002.

Mills, P. and Groening, C. (2021) "The Role of Social Acceptability and Guilt in Unethical Consumer Behavior: Following the Crowd or Their Own Moral Compass?," Journal of Business Research, 136, pp. 377--388. doi: 10.1016/j.jbusres.2021.07.021.

Nourbakhsh, I. R. (2021) "Ai Ethics: A Call to Faculty," Association for Computing Machinery. Communications of the ACM, 64(9), pp. 43--43. doi: 10.1145/3478516.

Reardon, J. et al. (2019) "A Global Consumer Decision Model of Intellectual Property Theft," Journal of Research in Interactive Marketing, 13(4), pp. 509--528. doi: 10.1108/JRIM-07-2018-0093.

Yan, M. (2019) "Corporate Social Responsibility Versus Shareholder Value Maximization: Through the Lens of Hard and Soft Law," Northwestern Journal of International Law & Business, 40(1), pp. 47--85.
