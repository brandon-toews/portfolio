[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Currently in my 2nd year of an Artificial Intelligence BSc program. I am particularly fascinated with Deep Learning and how to deploy it in the most easily consumable way. I‚Äôm thoroughly enjoying the education and journey along the way.\n\nAffiliations\nCurrent Student: Artificial Intelligence BSC, University of Gloucestershire\nPrevious Student: Network Administrator Specialist Diploma, Centre for Arts & Technology"
  },
  {
    "objectID": "posts/modes-of-motion/modes-of-motion.html",
    "href": "posts/modes-of-motion/modes-of-motion.html",
    "title": "Modes of Motion Programming Mathematics",
    "section": "",
    "text": "Play Demo\n\n\n\n\n\n\nCamera Keyboard Controls\n\n\n\n\n\n\n\n\nForward\nUp Arrow or W\nDown\nQ\n\n\nBackward\nDown Arrow or S\nLook Left\nZ\n\n\nStrafe Left\nLeft Arrow or A\nLook Right\nX\n\n\nStrafe Right\nRight Arrow or D\nLook Up\nR\n\n\nUp\nE\nLook Down\nF\n\n\nEscape Program\nEsc\n\n\n\n\n\nCamera Canvas\nWhen user clicks anywhere in the scene camera canvas is enabled allowing the user to do various camera movements based on the options they choose. In this mode the user can create a limited amount of cubes and spheres using the ‚ÄúCreate Cube‚Äù & ‚ÄúCreate Sphere‚Äù buttons.\nObject Canvas\nWhen an object is clicked on it is selected then the object canvas is enabled allowing the user to move the object using the various options they choose.\n\nüöÄ Play Demo\n\n\n\n\n\nModes of Motion\nProject to demonstrate various methods of movement within the Unity Games Engine, making use of my own linear interpolation (lerp) libraries and scripts using Unity physics all written in C#. This scene employs mathematical techniques like projectile formulas and equations that have been developed over the course of the module.\n\n\n\n\n\n\nSource Code\n\n\n\nView source code on Github repository.\n\n\n\n\nVideo Walkthrough\nVideo\n\n\nReferences\n\nUnity Documentation\nhttps://docs.unity3d.com/ScriptReference/index.html\n\n\nSpawning Objects\n\n\n\nCollision Detection\n\n\n\nSpecific Coding Problems Queried on:\nhttps://stackoverflow.com/questions/"
  },
  {
    "objectID": "posts/automation-sys-admin/automation-sys-admin.html#purpose-of-document",
    "href": "posts/automation-sys-admin/automation-sys-admin.html#purpose-of-document",
    "title": "Automation in Systems Administration Project",
    "section": "1.1 Purpose of Document",
    "text": "1.1 Purpose of Document\nThe purpose of this document is to provide an in-depth system analysis of the existing Tandoori Inc network and to propose designs for the upgrade and expansion of said network."
  },
  {
    "objectID": "posts/automation-sys-admin/automation-sys-admin.html#scope",
    "href": "posts/automation-sys-admin/automation-sys-admin.html#scope",
    "title": "Automation in Systems Administration Project",
    "section": "1.2 Scope",
    "text": "1.2 Scope\nThe scope of the project involves an examination of the current network to ascertain where it can be improved. In addition, design and implementation of the future expansion showing contrasts between current and future networks. The proposed solutions must include detailed configurations and address potential growth of the business in the future."
  },
  {
    "objectID": "posts/automation-sys-admin/automation-sys-admin.html#existing-network-analysis",
    "href": "posts/automation-sys-admin/automation-sys-admin.html#existing-network-analysis",
    "title": "Automation in Systems Administration Project",
    "section": "2.1 Existing Network Analysis",
    "text": "2.1 Existing Network Analysis\nThe existing network is located in Vancouver head office and utilizes 7 on-premises servers comprised of two (2) domain controllers, two (2) file servers, one (1) backup server, one (1) web server, and one (1) firewall/router. In addition, there is one (1) load balanced database server cluster and one (1) load balanced mail server cluster both deployed from AWS cloud infrastructure. There are seventy-five (75) work stations & laptops, seventy-two (72) BYOD phones all with antivirus software installed. All clients that do not require static IP addresses acquire there addresses from a DHCP server on the primary domain controller(Subnet and IP address table are shown in section 2.2 IP Address Table). The exception to this are the BYOD phones, they acquire their local IP addresses from the wireless access point. A local DNS is also installed on the primary domain server. The file servers are configured with a folder hierarchy consisting of a ‚ÄúCompanyData‚Äù folder containing four (4) departments, ‚ÄúAdministration‚Äù, ‚ÄúMarketing‚Äù, ‚ÄúSales‚Äù, and ‚ÄúIT‚Äù, all departments housing data in public and private folders. ( See Figure¬†1 )\n\n\n\n\n\n(a) IP Address Table\n\n\n\n\n\n(b) Network Diagram\n\n\nFigure¬†1. Existing Network"
  },
  {
    "objectID": "posts/automation-sys-admin/automation-sys-admin.html#future-proposed-network",
    "href": "posts/automation-sys-admin/automation-sys-admin.html#future-proposed-network",
    "title": "Automation in Systems Administration Project",
    "section": "3.1 Future / Proposed Network",
    "text": "3.1 Future / Proposed Network\nA new location in Kelowna will be setup as a branch office for Interior B.C. Seventeen (17) employees from the Vancouver branch will move to the Kelowna branch and fifteen (15) new empoyees will be hired locally. The new branch will require the addition of another subnet and servers to service the new location. The Kelowna branch will be connected to the head office at all times with all resources being available in both locations.\nIn addition, a new RnD department with it‚Äôs own subnet and Read-Only Domain Controller will be setup in the Vancouver branch. All workstations in the RnD Department network segment will acquire IP addresses from the DHCP server hosted on the primary domain controller in the Vancouver head office network. To minimize the WAN traffic the Kelowna branch will house the same amount and kind of servers that the Vancouver branch does allowing for the clients in the Kelowna network to access services in their own location. The Kelowna network will be comprised of two (2) domain controllers, two (2) file servers, one (1) backup server, one (1) web server, and one (1) firewall/router. The domain controllers, file servers, and web server will replicate from the Vancouver branch assuring that all company data and services are in sync across the organization. Active Directory will be updated to include the addition of the new branch and subsequent servers and client machines. A DFS will be setup for the entire business and the folder hierarchy for the previous file servers will be transferred to DFS based file services on the two (2) file servers located at the Vancouver branch. DFS file service must be accessible to RnD network but RnD is restricted to only one folder."
  },
  {
    "objectID": "posts/automation-sys-admin/automation-sys-admin.html#fault-tolerance-and-availability",
    "href": "posts/automation-sys-admin/automation-sys-admin.html#fault-tolerance-and-availability",
    "title": "Automation in Systems Administration Project",
    "section": "3.2 Fault Tolerance and Availability",
    "text": "3.2 Fault Tolerance and Availability\nActive Directory will be configured to regularly backup all crucial server data to the backup servers hosted in the network that they are located. Failover clusters for both the Vancouver and Kelowna network will be deployed in the company‚Äôs already existing AWS infrastructure. These clusters will employ load balancing technology and elastic provisioning should the on premises servers go offline. These strategies will allow for the new system to have excellent fault tolerance and high availability ensuring that the expanded network maintain a high quality of performance."
  },
  {
    "objectID": "posts/automation-sys-admin/automation-sys-admin.html#security",
    "href": "posts/automation-sys-admin/automation-sys-admin.html#security",
    "title": "Automation in Systems Administration Project",
    "section": "3.3 Security",
    "text": "3.3 Security\nEdge routers on both Vancouver and Kelowna networks with act as a firewall and router in one. Local firewalls on all servers and clients will also be configured for maximum protection. In addition, an Inter-Site VPN will be employed so that the Vancouver and Kelowna networks will have a secured/tunneled connection leaving it impossible for man-in-the-middle attacks to occur. Each branch will access the AWS infrastructure through a secure VPN connection as well. The VPN will be configured to utilize the highest level of security available without the need for certificates."
  },
  {
    "objectID": "posts/automation-sys-admin/automation-sys-admin.html#administration",
    "href": "posts/automation-sys-admin/automation-sys-admin.html#administration",
    "title": "Automation in Systems Administration Project",
    "section": "3.4 Administration",
    "text": "3.4 Administration\nFor administrative purposes, IT will be given access to all servers and administrative capabilities within the company by means of group policies employed in Active Directory. In addition to being able to perform their duties internally they will also be given administrative access externally through secure VPN connections. This will allow for quick responses to outages or emergencies that occur outside of office hours. Upstream and downstream WSUS servers will be used to ensure smooth updates and upgrades to the various servers and clients in the system. The upstream WSUS server will be hosted on the Primary Domain Controller (DC1.Van.Tandoori.Local) in the Vancouver network and will be managed by IT staff there. The downstream WSUS server will be provisioned on the Primary Domain Controller (DC1.Kel.Tandoori.Local) in the Kelowna network which will inherit update approvals from the upstream server housed in Vancouver. This configuration will save bandwidth on internet connections and allow for updates to be administered entirely by IT staff at head offices in Vancouver. Active Directory Group Policies will be used to implement software deployment and access for the various servers, client machines, and users in the network. Careful considerations will be given to what softwares and accesses will be afforded to the machines and users in the network to ensure that the principle of least privilege is adheard to. Therefore, only necessary software and necessary access will be provisioned using Group Policies in the Active Directory environment."
  },
  {
    "objectID": "posts/automation-sys-admin/automation-sys-admin.html#branchcache",
    "href": "posts/automation-sys-admin/automation-sys-admin.html#branchcache",
    "title": "Automation in Systems Administration Project",
    "section": "3.5 BranchCache",
    "text": "3.5 BranchCache\nTo optimize WAN bandwidth BranchCache technology will be utilized for company data. The two (2) file servers located at the Kelowna branch will be configured as hosted cache servers and will cache data housed in the file servers located at the Vancouver branch. This will allow for quick retrieval of company data for clients located in the Kelowna network and will ensure continuity of data across the entirety of the organization‚Äôs infrastructure."
  },
  {
    "objectID": "posts/automation-sys-admin/automation-sys-admin.html#future-network-ip-address-tables",
    "href": "posts/automation-sys-admin/automation-sys-admin.html#future-network-ip-address-tables",
    "title": "Automation in Systems Administration Project",
    "section": "3.6 Future Network ‚Äì IP Address Tables",
    "text": "3.6 Future Network ‚Äì IP Address Tables\nSubnets were designed in a way to allow for large amounts of room for growth. Both Vancouver and Kelowna networks were allocated a 16 bit address space to give plenty of room to add new departments or even resubnet the existing subnets to allow for more room if departments outgrow their allocated space. Even the subnets for each department were created very large (given a 24 bit address space) to allow for growth within the department. The RnD department network was given a 24 bit address space that well exceeds its need at this current time. ( See Figure¬†2 )\n\n\n\n\n\n(a) Vancouver Network Address Table\n\n\n\n\n\n(b) RnD Network Address Table\n\n\n\n\n\n(c) Kelowna Network Address Table\n\n\nFigure¬†2. Future Network ‚Äì IP Address Tables"
  },
  {
    "objectID": "posts/automation-sys-admin/automation-sys-admin.html#future-network-diagrams",
    "href": "posts/automation-sys-admin/automation-sys-admin.html#future-network-diagrams",
    "title": "Automation in Systems Administration Project",
    "section": "3.7 Future Network Diagrams",
    "text": "3.7 Future Network Diagrams\n\n\n\n\n\n(a) Full Network Diagram\n\n\n\n\n\n(b) Vancouver Network Diagram\n\n\n\n\n\n(c) Kelowna Network Diagram\n\n\nFigure¬†3. Future Network Diagrams"
  },
  {
    "objectID": "posts/automation-sys-admin/automation-sys-admin.html#directaccess",
    "href": "posts/automation-sys-admin/automation-sys-admin.html#directaccess",
    "title": "Automation in Systems Administration Project",
    "section": "4.1 DirectAccess",
    "text": "4.1 DirectAccess\nEven though the internet will eventually move towards IPv6 only, by and large IPv4 is still predominantly used today. This presents a problem because when your company makes the switch you will have communication issues with external clients using IPv4 that try to access your services. DirectAccess uses IPv6 transition protocols to facilitate communications with IPv4 connections. In my professional opinion I believe you should invest your time and energy into converting soon and using DirectAccess to address the communications issues that come with it. However, I think you should implement the pending network expansion first and allow the company time to adjust to the new infrastructure before making the switch. After 2 ‚Äì 5 years operating with the new branch network and RnD department network your IT team should have all of the major issues worked out, giving you the right circumstances to move ahead with transitioning to IPv6. Please consult the references to DirectAccess technology posted in the Appendix of this document to become more familiar with the process and to help you make an informed decision."
  },
  {
    "objectID": "posts/automation-sys-admin/automation-sys-admin.html#references",
    "href": "posts/automation-sys-admin/automation-sys-admin.html#references",
    "title": "Automation in Systems Administration Project",
    "section": "References",
    "text": "References\n\nDirectAccess\nhttps://docs.microsoft.com/en-us/windows-server/remote/remote-access/directaccess/single-server-wizard/da-basic-plan-s1-infrastructure\nhttps://directaccess.richardhicks.com/2014/10/28/directaccess-ipv6-transition-protocols-explained/\n\n\nWSUS Servers\nhttps://docs.microsoft.com/de-de/security-updates/windowsupdateservices/18127375\nhttps://askme4tech.com/how-install-configure-wsus-downstream-server-windows-server-2016\n\n\nBranchCache\nhttps://docs.microsoft.com/en-us/windows-server/networking/branchcache/branchcache\n\n\nPrinciple of Least Priviledge\nhttps://www.cisa.gov/uscert/bsi/articles/knowledge/principles/least-privilege"
  },
  {
    "objectID": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#purpose-of-document",
    "href": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#purpose-of-document",
    "title": "Linear Regression, Classification, Clustering",
    "section": "1.1 Purpose of Document",
    "text": "1.1 Purpose of Document\nThe purpose of this document is to provide a comparison between different AI models for a given dataset to determine which models are most accurate. This document also explores what measures can be taken to improve accuracy in various AI models."
  },
  {
    "objectID": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#scope",
    "href": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#scope",
    "title": "Linear Regression, Classification, Clustering",
    "section": "1.2 Scope",
    "text": "1.2 Scope\nThe scope of the project involves an exploratory examination of a dataset to determine how best to sample and clean the data for AI training and testing purposes. Various data visualizations are needed to properly understand the dataset and how best to proceed with training models. Training of various models and algorithms are required to produce sufficient comparisons with the ultimate goal of improving accuracy."
  },
  {
    "objectID": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#descriptive-analysis",
    "href": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#descriptive-analysis",
    "title": "Linear Regression, Classification, Clustering",
    "section": "2.1 Descriptive Analysis",
    "text": "2.1 Descriptive Analysis\nThe dataset used in this project consists of available independent variables for a variety of cars to ascertain how they affect the price. The chosen dataset contains 26 columns and 205 rows of data with no null values. It is a sufficient dataset in terms of size and types of data for use in training univariate & multivariate linear regression, classification and clustering models.\nThe Columns\n\nCar_ID : Unique id of each observation (Integer)\nSymboling : Its assigned insurance risk rating, A value of +3 - Indicates that the auto is risky, -3 that it is probably pretty safe.\ncarCompany : Name of car company (Categorical)\nfueltype : Car fuel type i.e gas or diesel (Categorical)\naspiration : Aspiration used in a car (Categorical)\ndoornumber : Number of doors in a car (Categorical)\ncarbody : Body of car (Categorical)\ndrivewheel : Type of drive wheel (Categorical)\nenginelocation : Location of car engine (Categorical)\nwheelbase : Wheelbase of car (Numeric)\ncarlength : Length of car (Numeric)\ncarwidth : Width of car (Numeric)\ncarheight : Height of car (Numeric)\ncurbweight : The weight of a car without occupants or baggage. (Numeric)\nenginetype : Type of engine. (Categorical)\ncylindernumber : Cylinder placed in the car (Numeric)\nenginesize : Size of car (Numeric)\nfuelsystem : Fuel system of car (Categorical)\nboreratio : Boreratio of car (Numeric)\nstroke : Stroke or volume inside the engine (Numeric)\ncompressionratio : Compression ratio of car (Numeric)\nhorsepower : Horsepower (Numeric)\npeakrpm : Car peak rpm (Numeric)\ncitympg : Mileage in city (Numeric)\nhighwaympg : Mileage on highway (Numeric)\nprice(Dependent variable) : Price of car (Numeric)\n\n\n\nCode\n# Import libraries for analysis and plotting\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n\n# Save data in Pandas dataframe\ndataset = pd.read_csv(\"CarPrice_Assignment.csv\")\n\n# Print how many rows and columns are in dataset\nprint('Dataset Shape:',dataset.shape)\n\n# Turn of max columns so that head() displays all columns in dataset\npd.set_option('display.max_columns', None)\n\npd.set_option('display.max_rows', 5)\n\n# Display 1st five entries of dataset\ndataset.head()\n\n\nDataset Shape: (205, 26)\n\n\n\n\n\n\n\n\n\ncar_ID\nsymboling\nCarName\nfueltype\naspiration\ndoornumber\ncarbody\ndrivewheel\nenginelocation\nwheelbase\ncarlength\ncarwidth\ncarheight\ncurbweight\nenginetype\ncylindernumber\nenginesize\nfuelsystem\nboreratio\nstroke\ncompressionratio\nhorsepower\npeakrpm\ncitympg\nhighwaympg\nprice\n\n\n\n\n0\n1\n3\nalfa-romero giulia\ngas\nstd\ntwo\nconvertible\nrwd\nfront\n88.6\n168.8\n64.1\n48.8\n2548\ndohc\nfour\n130\nmpfi\n3.47\n2.68\n9.0\n111\n5000\n21\n27\n13495.0\n\n\n1\n2\n3\nalfa-romero stelvio\ngas\nstd\ntwo\nconvertible\nrwd\nfront\n88.6\n168.8\n64.1\n48.8\n2548\ndohc\nfour\n130\nmpfi\n3.47\n2.68\n9.0\n111\n5000\n21\n27\n16500.0\n\n\n2\n3\n1\nalfa-romero Quadrifoglio\ngas\nstd\ntwo\nhatchback\nrwd\nfront\n94.5\n171.2\n65.5\n52.4\n2823\nohcv\nsix\n152\nmpfi\n2.68\n3.47\n9.0\n154\n5000\n19\n26\n16500.0\n\n\n3\n4\n2\naudi 100 ls\ngas\nstd\nfour\nsedan\nfwd\nfront\n99.8\n176.6\n66.2\n54.3\n2337\nohc\nfour\n109\nmpfi\n3.19\n3.40\n10.0\n102\n5500\n24\n30\n13950.0\n\n\n4\n5\n2\naudi 100ls\ngas\nstd\nfour\nsedan\n4wd\nfront\n99.4\n176.6\n66.4\n54.3\n2824\nohc\nfive\n136\nmpfi\n3.19\n3.40\n8.0\n115\n5500\n18\n22\n17450.0\n\n\n\n\n\n\n\n\n\nCode\n# Print data types and how many null values are present\ndataset.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 205 entries, 0 to 204\nData columns (total 26 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   car_ID            205 non-null    int64  \n 1   symboling         205 non-null    int64  \n 2   CarName           205 non-null    object \n 3   fueltype          205 non-null    object \n 4   aspiration        205 non-null    object \n 5   doornumber        205 non-null    object \n 6   carbody           205 non-null    object \n 7   drivewheel        205 non-null    object \n 8   enginelocation    205 non-null    object \n 9   wheelbase         205 non-null    float64\n 10  carlength         205 non-null    float64\n 11  carwidth          205 non-null    float64\n 12  carheight         205 non-null    float64\n 13  curbweight        205 non-null    int64  \n 14  enginetype        205 non-null    object \n 15  cylindernumber    205 non-null    object \n 16  enginesize        205 non-null    int64  \n 17  fuelsystem        205 non-null    object \n 18  boreratio         205 non-null    float64\n 19  stroke            205 non-null    float64\n 20  compressionratio  205 non-null    float64\n 21  horsepower        205 non-null    int64  \n 22  peakrpm           205 non-null    int64  \n 23  citympg           205 non-null    int64  \n 24  highwaympg        205 non-null    int64  \n 25  price             205 non-null    float64\ndtypes: float64(8), int64(8), object(10)\nmemory usage: 41.8+ KB\n\n\n\n\nCode\n# Display some descriptive statistics\ndataset.describe().round(2)\n\n\n\n\n\n\n\n\n\ncar_ID\nsymboling\nwheelbase\ncarlength\ncarwidth\ncarheight\ncurbweight\nenginesize\nboreratio\nstroke\ncompressionratio\nhorsepower\npeakrpm\ncitympg\nhighwaympg\nprice\n\n\n\n\ncount\n205.00\n205.00\n205.00\n205.00\n205.00\n205.00\n205.00\n205.00\n205.00\n205.00\n205.00\n205.00\n205.00\n205.00\n205.00\n205.00\n\n\nmean\n103.00\n0.83\n98.76\n174.05\n65.91\n53.72\n2555.57\n126.91\n3.33\n3.26\n10.14\n104.12\n5125.12\n25.22\n30.75\n13276.71\n\n\nstd\n59.32\n1.25\n6.02\n12.34\n2.15\n2.44\n520.68\n41.64\n0.27\n0.31\n3.97\n39.54\n476.99\n6.54\n6.89\n7988.85\n\n\nmin\n1.00\n-2.00\n86.60\n141.10\n60.30\n47.80\n1488.00\n61.00\n2.54\n2.07\n7.00\n48.00\n4150.00\n13.00\n16.00\n5118.00\n\n\n25%\n52.00\n0.00\n94.50\n166.30\n64.10\n52.00\n2145.00\n97.00\n3.15\n3.11\n8.60\n70.00\n4800.00\n19.00\n25.00\n7788.00\n\n\n50%\n103.00\n1.00\n97.00\n173.20\n65.50\n54.10\n2414.00\n120.00\n3.31\n3.29\n9.00\n95.00\n5200.00\n24.00\n30.00\n10295.00\n\n\n75%\n154.00\n2.00\n102.40\n183.10\n66.90\n55.50\n2935.00\n141.00\n3.58\n3.41\n9.40\n116.00\n5500.00\n30.00\n34.00\n16503.00\n\n\nmax\n205.00\n3.00\n120.90\n208.10\n72.30\n59.80\n4066.00\n326.00\n3.94\n4.17\n23.00\n288.00\n6600.00\n49.00\n54.00\n45400.00"
  },
  {
    "objectID": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#cleaning",
    "href": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#cleaning",
    "title": "Linear Regression, Classification, Clustering",
    "section": "2.2 Cleaning",
    "text": "2.2 Cleaning\nMultiple columns are object data types but for classification and clustering purposes they were converted to category types. Column 16, ‚Äúcylindernumber‚Äù, values were changed from strings to integers to assist in training some of the linear regression models.\n\n\nCode\n# Convert object data types to category types\ndataset['CarName'] = dataset['CarName'].astype('category')\ndataset['fueltype'] = dataset['fueltype'].astype('category')\ndataset['aspiration'] = dataset['aspiration'].astype('category')\ndataset['doornumber'] = dataset['doornumber'].astype('category')\ndataset['carbody'] = dataset['carbody'].astype('category')\ndataset['drivewheel'] = dataset['drivewheel'].astype('category')\ndataset['enginelocation'] = dataset['enginelocation'].astype('category')\ndataset['enginetype'] = dataset['enginetype'].astype('category')\ndataset['fuelsystem'] = dataset['fuelsystem'].astype('category')\ndataset['curbweight'] = dataset['curbweight'].astype('int')\n\n# Convert strings to integers in cylindernumber column to potentially use in the regression models\ndataset['cylindernumber'] = dataset['cylindernumber'].replace(['two'], 2).replace(['three'], 3)\\\n.replace(['four'], 4).replace(['five'], 5).replace(['six'], 6).replace(['eight'], 8).replace(['twelve'], 12)\n\ndataset.head()\n\n\n\n\n\n\n\n\n\ncar_ID\nsymboling\nCarName\nfueltype\naspiration\ndoornumber\ncarbody\ndrivewheel\nenginelocation\nwheelbase\ncarlength\ncarwidth\ncarheight\ncurbweight\nenginetype\ncylindernumber\nenginesize\nfuelsystem\nboreratio\nstroke\ncompressionratio\nhorsepower\npeakrpm\ncitympg\nhighwaympg\nprice\n\n\n\n\n0\n1\n3\nalfa-romero giulia\ngas\nstd\ntwo\nconvertible\nrwd\nfront\n88.6\n168.8\n64.1\n48.8\n2548\ndohc\n4\n130\nmpfi\n3.47\n2.68\n9.0\n111\n5000\n21\n27\n13495.0\n\n\n1\n2\n3\nalfa-romero stelvio\ngas\nstd\ntwo\nconvertible\nrwd\nfront\n88.6\n168.8\n64.1\n48.8\n2548\ndohc\n4\n130\nmpfi\n3.47\n2.68\n9.0\n111\n5000\n21\n27\n16500.0\n\n\n2\n3\n1\nalfa-romero Quadrifoglio\ngas\nstd\ntwo\nhatchback\nrwd\nfront\n94.5\n171.2\n65.5\n52.4\n2823\nohcv\n6\n152\nmpfi\n2.68\n3.47\n9.0\n154\n5000\n19\n26\n16500.0\n\n\n3\n4\n2\naudi 100 ls\ngas\nstd\nfour\nsedan\nfwd\nfront\n99.8\n176.6\n66.2\n54.3\n2337\nohc\n4\n109\nmpfi\n3.19\n3.40\n10.0\n102\n5500\n24\n30\n13950.0\n\n\n4\n5\n2\naudi 100ls\ngas\nstd\nfour\nsedan\n4wd\nfront\n99.4\n176.6\n66.4\n54.3\n2824\nohc\n5\n136\nmpfi\n3.19\n3.40\n8.0\n115\n5500\n18\n22\n17450.0\n\n\n\n\n\n\n\n\n\nCode\n# Print new data types and how many null values are present\ndataset.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 205 entries, 0 to 204\nData columns (total 26 columns):\n #   Column            Non-Null Count  Dtype   \n---  ------            --------------  -----   \n 0   car_ID            205 non-null    int64   \n 1   symboling         205 non-null    int64   \n 2   CarName           205 non-null    category\n 3   fueltype          205 non-null    category\n 4   aspiration        205 non-null    category\n 5   doornumber        205 non-null    category\n 6   carbody           205 non-null    category\n 7   drivewheel        205 non-null    category\n 8   enginelocation    205 non-null    category\n 9   wheelbase         205 non-null    float64 \n 10  carlength         205 non-null    float64 \n 11  carwidth          205 non-null    float64 \n 12  carheight         205 non-null    float64 \n 13  curbweight        205 non-null    int64   \n 14  enginetype        205 non-null    category\n 15  cylindernumber    205 non-null    int64   \n 16  enginesize        205 non-null    int64   \n 17  fuelsystem        205 non-null    category\n 18  boreratio         205 non-null    float64 \n 19  stroke            205 non-null    float64 \n 20  compressionratio  205 non-null    float64 \n 21  horsepower        205 non-null    int64   \n 22  peakrpm           205 non-null    int64   \n 23  citympg           205 non-null    int64   \n 24  highwaympg        205 non-null    int64   \n 25  price             205 non-null    float64 \ndtypes: category(9), float64(8), int64(9)\nmemory usage: 36.1 KB"
  },
  {
    "objectID": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#visualizations",
    "href": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#visualizations",
    "title": "Linear Regression, Classification, Clustering",
    "section": "2.3 Visualizations",
    "text": "2.3 Visualizations\nA pairplot ( See Figure 1 ) provides a quick overview of how the variables relate, showing some possibilities for training models. The ‚Äòcarbody‚Äô ( See Figure 2 ) and ‚Äòfueltype‚Äô ( See Figure 3 ) columns show promise for use with the classification and clustering models ( See Figure 4 (f) & Figure 4 (g) ). Clear linear relationships exist between ‚Äòcarlength‚Äô, ‚Äòcarwidth‚Äô, ‚Äòcurbweight‚Äô, ‚Äòenginesize‚Äô, ‚Äòcylindernumber‚Äô and ‚Äòhorsepower‚Äô independent variables and the dependent variable ‚Äòprice‚Äô ( See Figure 4 (a) - (f) ).\n\n\nCode\n# Display a pairplot to quickly see how varaiables relate to one another with 'fueltype' hue\nsns.pairplot(dataset, kind= 'scatter', hue= 'fueltype')\nplt.show()\n\n\n\n\n\nFigure¬†1. Pairplot with Fuel Type Hue\n\n\n\n\n\n\nCode\n# display pie chart data for carbody\ndataset['carbody'].value_counts().plot.pie(autopct='%1.3f%%');\n\n# Display relationship between body style and price\ndataset.groupby('carbody')['price'].mean().round(2)\n\n\n\n\n\nFigure¬†2. Carbody Pie Plot\n\n\n\n\n\n\ncarbody\nconvertible    21890.50\nhardtop        22208.50\nhatchback      10376.65\nsedan          14344.27\nwagon          12371.96\nName: price, dtype: float64\n\n\n\n\nCode\n# display pie chart data for fueltype\ndataset['fueltype'].value_counts().plot.pie(autopct='%1.3f%%');\n\n# Display ralationship between body style and price\ndataset.groupby('fueltype')['price'].mean().round(2)\n\n\n\n\n\nFigure¬†3. Fuel Type Pie Plot\n\n\n\n\n\n\nfueltype\ndiesel    15838.15\ngas       12999.80\nName: price, dtype: float64\n\n\n\n\nCode\n# Carlength has moderate relationship to price\nplt.figure(figsize=(6,6));\nsns.regplot(data=dataset, x=\"carlength\", y=\"price\");\n\n# Carwidth has moderate relationship to price\nplt.figure(figsize=(6,6));\nsns.regplot(data=dataset, x=\"carwidth\", y=\"price\");\n\n# Carweight has moderate/strong relationship to price\nplt.figure(figsize=(6,6));\nsns.regplot(data=dataset, x=\"curbweight\", y=\"price\");\n\n# Engine size has strong relationship to price\nsns.lmplot(data=dataset, x=\"enginesize\", y=\"price\", hue='fueltype', height=6)\n\n# Horsepower has strong relationship to price for both fuel types\nsns.lmplot(data=dataset, x=\"horsepower\", y=\"price\", hue='fueltype', height=6)\n\n# Cylinder number has moderate/strong relationship to price\nsns.jointplot(data=dataset, x=\"cylindernumber\", y=\"price\", kind=\"reg\");\n\n# Clear classification relationship between compressionratio and fueltype\ng = sns.jointplot(data=dataset, x=\"compressionratio\", y=\"price\", hue='fueltype');\ng.plot_joint(sns.kdeplot, hue='fueltype');\n\n\n\n\n\n\n\n\n(a) Car Length vs Price\n\n\n\n\n\n\n\n(b) Car Width vs Price\n\n\n\n\n\n\n\n\n\n(c) Curb Weight vs Price\n\n\n\n\n\n\n\n(d) Engine Size vs Price\n\n\n\n\n\n\n\n\n\n(e) Horsepower vs Price\n\n\n\n\n\n\n\n(f) Cylinder Number vs Price\n\n\n\n\n\n\n\n\n\n(g) Compression Ratio vs Price\n\n\n\n\nFigure¬†4. Plots for visualizing"
  },
  {
    "objectID": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#univariate-models",
    "href": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#univariate-models",
    "title": "Linear Regression, Classification, Clustering",
    "section": "3.1 Univariate Models",
    "text": "3.1 Univariate Models\nMultiple univariate models were trained for comparison using a custom Linear Regression training function. Models were trained with ‚Äòcarlength‚Äô, ‚Äòcarwidth‚Äô, ‚Äòcurbweight‚Äô, ‚Äòcylindernumber‚Äô, ‚Äòenginesize‚Äô and ‚Äòhorsepower‚Äô independent variables. In most cases the model accuracy was the best with a 70% training and 30% testing split ( See Items 3.1.1 - 3.1.4 ). However, with engine size and horsepower models more accuracy was achieved with an 80% training and 20% testing split ( See Items 3.1.5 - 3.1.6 ).\n\n\nCode\n# Import regression training libraries and packages\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\n\n\n# Linear Regression training function that takes in X and Y arguments and displays results\ndef myLinRegModel(x, y, testSize):\n    \n    # While loop to iterate every 10% from given test size\n    while testSize&gt;0:\n        \n        # Splitting data into training and testing variables using the values passed into function\n        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=(testSize/100), random_state=0)\n\n        # Training model with LinearRegression function and training data\n        regressor = LinearRegression()\n        regressor.fit(x_train, y_train)\n    \n        # Print test size of current iteration\n        print('Test Size:', testSize, '%\\n')\n\n        # Print intercept and CoEfficient values of model\n        print(\"a =\", regressor.intercept_)\n        print(\"b =\", regressor.coef_)\n\n        # Test the trained model with test data and store in variable\n        y_pred = regressor.predict(x_test)\n\n        # Display predicted values next to actual values for comparison\n        df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n        print(df)\n    \n        # Display accuracy of model predictions in the form of Mean Absolute Error, Mean Squared Error,\n        # Root Mean Squared Error using the difference between actual and predicted values\n        print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n        print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n        print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n        print('R2 Score: ', metrics.r2_score(y_test,y_pred)*100, '%\\n', sep='')\n        \n        # Decrease test size by 10\n        testSize -= 10\n\n\n\n3.1.1 Car Length vs Price\n\n\nCode\n# Carlength Column\ncarLength = dataset.iloc[:, 10:-15].values\n\n# Price Column\nprice = dataset.iloc[:, 25].values.round(2)\n\n# Call custom regression model function with 30% test size\nmyLinRegModel(carLength, price, 30)\n\n\nTest Size: 30 %\n\na = -63541.11342037626\nb = [440.33603117]\n     Actual     Predicted\n0    6795.0   6516.349139\n1   15750.0  19153.993234\n..      ...           ...\n60   6479.0    131.476687\n61  15510.0  18625.589997\n\n[62 rows x 2 columns]\nMean Absolute Error: 3981.584437549869\nMean Squared Error: 32715085.38508641\nRoot Mean Squared Error: 5719.71025359558\nR2 Score: 50.45973947401606%\n\nTest Size: 20 %\n\na = -63738.09854118214\nb = [441.42013341]\n     Actual     Predicted\n0    6795.0   6491.844685\n1   15750.0  19160.602514\n..      ...           ...\n39  45400.0  24192.792035\n40   8916.5   5079.300258\n\n[41 rows x 2 columns]\nMean Absolute Error: 4528.295484564718\nMean Squared Error: 43469954.12056989\nRoot Mean Squared Error: 6593.174813439266\nR2 Score: 43.84913586892223%\n\nTest Size: 10 %\n\na = -66742.8631493445\nb = [459.19742348]\n     Actual     Predicted\n0    6795.0   6315.446927\n1   15750.0  19494.412981\n..      ...           ...\n19   6488.0   6131.767957\n20   9959.0  12698.291113\n\n[21 rows x 2 columns]\nMean Absolute Error: 3945.9317457788898\nMean Squared Error: 29396652.85426334\nRoot Mean Squared Error: 5421.868022578873\nR2 Score: 26.410928631260454%\n\n\n\n\n\n3.1.2 Car Width vs Price\n\n\nCode\n# Carwidth Column\ncarWidth = dataset.iloc[:, 11:-14].values\n\n# Price Column\nprice = dataset.iloc[:, 25].values.round(2)\n\n# Call custom regression model function with 30% test size\nmyLinRegModel(carWidth, price, 30)\n\n\nTest Size: 30 %\n\na = -172630.60948546475\nb = [2822.14912394]\n     Actual     Predicted\n0    6795.0   8551.364271\n1   15750.0  15042.307256\n..      ...           ...\n60   6479.0   7704.719534\n61  15510.0  15042.307256\n\n[62 rows x 2 columns]\nMean Absolute Error: 3036.57768015824\nMean Squared Error: 22710512.087679498\nRoot Mean Squared Error: 4765.554751304354\nR2 Score: 65.60960571372881%\n\nTest Size: 20 %\n\na = -172526.22359994025\nb = [2819.03318321]\n     Actual     Predicted\n0    6795.0   8455.706762\n1   15750.0  14939.483084\n..      ...           ...\n39  45400.0  30444.165591\n40   8916.5   6764.286852\n\n[41 rows x 2 columns]\nMean Absolute Error: 3674.9155902799166\nMean Squared Error: 31370813.470780104\nRoot Mean Squared Error: 5600.965405247573\nR2 Score: 59.47779746918066%\n\nTest Size: 10 %\n\na = -181627.87173597398\nb = [2957.89666431]\n     Actual     Predicted\n0    6795.0   8269.094113\n1   15750.0  15072.256441\n..      ...           ...\n19   6488.0   6494.356114\n20   9959.0  11818.570110\n\n[21 rows x 2 columns]\nMean Absolute Error: 3197.214272696799\nMean Squared Error: 19783555.22362383\nRoot Mean Squared Error: 4447.87086409035\nR2 Score: 50.47553663690271%\n\n\n\n\n\n3.1.3 Curb Weight vs Price\n\n\nCode\n# Curbweight Column\ncarWeight = dataset.iloc[:, 13:-12].values\n\n# Price Column\nprice = dataset.iloc[:, 25].values.round(2)\n\n# Call custom regression model function with 30% test size\nmyLinRegModel(carWeight, price, 30)\n\n\nTest Size: 30 %\n\na = -18679.037713196016\nb = [12.40359272]\n     Actual     Predicted\n0    6795.0   4949.806413\n1   15750.0  20404.682939\n..      ...           ...\n60   6479.0   2568.316611\n61  15510.0  15530.071001\n\n[62 rows x 2 columns]\nMean Absolute Error: 2670.404540077829\nMean Squared Error: 18443910.151758883\nRoot Mean Squared Error: 4294.637371392244\nR2 Score: 72.0704958192619%\n\nTest Size: 20 %\n\na = -18833.605447325583\nb = [12.47623193]\n     Actual     Predicted\n0    6795.0   4933.616372\n1   15750.0  20479.001353\n..      ...           ...\n39  45400.0  27515.596159\n40   8916.5   4546.853183\n\n[41 rows x 2 columns]\nMean Absolute Error: 3256.3206631106873\nMean Squared Error: 25249391.034916148\nRoot Mean Squared Error: 5024.877215904499\nR2 Score: 67.3849408384091%\n\nTest Size: 10 %\n\na = -19880.405624111718\nb = [12.9537027]\n     Actual     Predicted\n0    6795.0   4796.398026\n1   15750.0  20936.711595\n..      ...           ...\n19   6488.0   6221.305324\n20   9959.0  10819.869783\n\n[21 rows x 2 columns]\nMean Absolute Error: 2695.197926817389\nMean Squared Error: 11737364.677960433\nRoot Mean Squared Error: 3425.9837533123873\nR2 Score: 70.61768320191304%\n\n\n\n\n\n3.1.4 Cylinder Number vs Price\n\n\nCode\n# Cylinder Number Column\ncylinderNumber = dataset.iloc[:, 15:-10].values\n\n# Price Column\nprice = dataset.iloc[:, 25].values.round(2)\n\n# Call custom regression model function with 30% test size\nmyLinRegModel(cylinderNumber, price, 30)\n\n\nTest Size: 30 %\n\na = -8750.74345729567\nb = [5045.13677503]\n     Actual     Predicted\n0    6795.0  11429.803643\n1   15750.0  21520.077193\n..      ...           ...\n60   6479.0  11429.803643\n61  15510.0  11429.803643\n\n[62 rows x 2 columns]\nMean Absolute Error: 3944.3868255082953\nMean Squared Error: 26684225.038138304\nRoot Mean Squared Error: 5165.677597192676\nR2 Score: 59.59223566856468%\n\nTest Size: 20 %\n\na = -9046.162097201766\nb = [5112.35112126]\n     Actual     Predicted\n0    6795.0  11403.242388\n1   15750.0  21627.944630\n..      ...           ...\n39  45400.0  31852.646873\n40   8916.5  11403.242388\n\n[41 rows x 2 columns]\nMean Absolute Error: 4280.5628888250285\nMean Squared Error: 32605207.611888204\nRoot Mean Squared Error: 5710.096987958103\nR2 Score: 57.88330998687709%\n\nTest Size: 10 %\n\na = -10564.254121382277\nb = [5479.84028365]\n     Actual     Predicted\n0    6795.0  11355.107013\n1   15750.0  22314.787580\n..      ...           ...\n19   6488.0  11355.107013\n20   9959.0  11355.107013\n\n[21 rows x 2 columns]\nMean Absolute Error: 3464.088015146232\nMean Squared Error: 18346836.560473613\nRoot Mean Squared Error: 4283.32073985519\nR2 Score: 54.072095495610604%\n\n\n\n\n\n3.1.5 Engine Size vs Price\n\n\nCode\n# Engine Size Column\nengineSize = dataset['enginesize'].values.reshape(-1, 1)\n\n# Price Column\nprice = dataset.iloc[:, 25].values.round(2)\n\n# Call custom regression model function with 30% test size\nmyLinRegModel(engineSize, price, 30)\n\n\nTest Size: 30 %\n\na = -7574.131488222356\nb = [163.29075344]\n     Actual     Predicted\n0    6795.0   7285.327074\n1   15750.0  18715.679815\n..      ...           ...\n60   6479.0   7448.617828\n61  15510.0  12184.049678\n\n[62 rows x 2 columns]\nMean Absolute Error: 2898.9726929694702\nMean Squared Error: 14541824.65222288\nRoot Mean Squared Error: 3813.374444271488\nR2 Score: 77.97940083865093%\n\nTest Size: 20 %\n\na = -7613.370926304753\nb = [164.31545176]\n     Actual     Predicted\n0    6795.0   7339.335184\n1   15750.0  18841.416808\n..      ...           ...\n39  45400.0  42338.526410\n40   8916.5   7175.019732\n\n[41 rows x 2 columns]\nMean Absolute Error: 3195.031241401546\nMean Squared Error: 16835544.028987687\nRoot Mean Squared Error: 4103.113942969131\nR2 Score: 78.25324722629195%\n\nTest Size: 10 %\n\na = -8207.420855494747\nb = [169.490971]\n     Actual     Predicted\n0    6795.0   7216.257505\n1   15750.0  19080.625475\n..      ...           ...\n19   6488.0   7385.748476\n20   9959.0  10436.585954\n\n[21 rows x 2 columns]\nMean Absolute Error: 2877.111549011615\nMean Squared Error: 12997474.409783443\nRoot Mean Squared Error: 3605.2010221045157\nR2 Score: 67.46323206602058%\n\n\n\n\n\n3.1.6 Horsepower vs Price\n\n\nCode\n# Horsepower Column\nhorsepower = dataset.iloc[:, 21:-4].values\n\n# Price Column\nprice = dataset.iloc[:, 25].values.round(2)\n\n# Call custom regression model function with 30% test size\nmyLinRegModel(horsepower, price, 30)\n\n\nTest Size: 30 %\n\na = -4438.686268723588\nb = [170.53827527]\n     Actual     Predicted\n0    6795.0   7157.916450\n1   15750.0  22165.284674\n..      ...           ...\n60   6479.0   5452.533697\n61  15510.0  14320.524011\n\n[62 rows x 2 columns]\nMean Absolute Error: 3518.2488303322393\nMean Squared Error: 25821021.51495541\nRoot Mean Squared Error: 5081.438921698795\nR2 Score: 60.89937966412712%\n\nTest Size: 20 %\n\na = -4053.153036276188\nb = [166.64923709]\n     Actual     Predicted\n0    6795.0   7278.995086\n1   15750.0  21944.127950\n..      ...           ...\n39  45400.0  26610.306588\n40   8916.5   7612.293560\n\n[41 rows x 2 columns]\nMean Absolute Error: 3733.6933754512147\nMean Squared Error: 29626244.692692798\nRoot Mean Squared Error: 5442.999604325983\nR2 Score: 61.73128603174041%\n\nTest Size: 10 %\n\na = -4796.241165629246\nb = [174.95075436]\n     Actual     Predicted\n0    6795.0   7100.410131\n1   15750.0  22496.076514\n..      ...           ...\n19   6488.0   6050.705605\n20   9959.0  15498.046340\n\n[21 rows x 2 columns]\nMean Absolute Error: 3839.1982159225827\nMean Squared Error: 26172943.363739382\nRoot Mean Squared Error: 5115.949898478227\nR2 Score: 34.48088778430891%"
  },
  {
    "objectID": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#multivariate-models",
    "href": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#multivariate-models",
    "title": "Linear Regression, Classification, Clustering",
    "section": "3.2 Multivariate Models",
    "text": "3.2 Multivariate Models\nMultiple univariate models were trained for comparison using a custom Linear Regression training function. Accuracy varies in each model with changes in training/test splits and would most likely would be benefitted with more rows of data ( See Items 3.2.1 - 3.2.3 ). The highest accurracy is seen with the model that takes in the most columns for the independent variables ( See Items 3.2.3 ).\n\n3.2.1 Carlength, Carwidth, Curbweight vs Price\n\n\nCode\n# Create copy of dataset and drop all columns not used for multivariate regression models\ndatasetCopy = dataset\ndatasetCopy.drop(['carheight', 'enginetype', 'fuelsystem', 'boreratio', 'stroke', 'compressionratio'],\\\ninplace=True, axis=1)\n\n# Store carlength, carwidth & curbweight columns in X\nX1 = datasetCopy.iloc[:, 10:-7].values\n\n# Call Regression Model Function with multiple x values & 30% test size\nmyLinRegModel(X1, price, 30)\n\n\nTest Size: 30 %\n\na = -36739.21951780665\nb = [-208.48890057  764.98885537   13.97180015]\n     Actual     Predicted\n0    6795.0   5818.760203\n1   15750.0  19003.466111\n..      ...           ...\n60   6479.0   5929.766976\n61  15510.0  13762.735333\n\n[62 rows x 2 columns]\nMean Absolute Error: 2458.5442776902337\nMean Squared Error: 16492573.815910544\nRoot Mean Squared Error: 4061.1049993703123\nR2 Score: 75.02539290462342%\n\nTest Size: 20 %\n\na = -44634.67127094674\nb = [-188.42001434  856.204069     13.34802623]\n     Actual     Predicted\n0    6795.0   5783.995638\n1   15750.0  18977.251262\n..      ...           ...\n39  45400.0  29066.672270\n40   8916.5   5459.428429\n\n[41 rows x 2 columns]\nMean Absolute Error: 2943.0381053387778\nMean Squared Error: 22423198.502769\nRoot Mean Squared Error: 4735.313981434494\nR2 Score: 71.03558082852051%\n\nTest Size: 10 %\n\na = -51021.53652492876\nb = [-194.19115484  961.28023332   13.59661598]\n     Actual     Predicted\n0    6795.0   5698.395155\n1   15750.0  19277.437054\n..      ...           ...\n19   6488.0   6694.931234\n20   9959.0  10475.100811\n\n[21 rows x 2 columns]\nMean Absolute Error: 2357.566870487648\nMean Squared Error: 9101964.422986511\nRoot Mean Squared Error: 3016.9462081691995\nR2 Score: 77.21491923452972%\n\n\n\n\n\n3.2.2 Cylinder Number, Engine Size, Horsepower vs Price\n\n\nCode\n# Store cylindernumber, enginesize & horsepower columns in X\nX2 = datasetCopy.iloc[:, 13:-4].values\n\n# Call Regression Model Function with multiple x values & 30% test size\nmyLinRegModel(X2, price, 30)\n\n\nTest Size: 30 %\n\na = -6717.131795698624\nb = [-875.82889691  133.38667558   65.31455209]\n     Actual     Predicted\n0    6795.0   6359.129636\n1   15750.0  19692.219717\n..      ...           ...\n60   6479.0   5839.370791\n61  15510.0  13103.941091\n\n[62 rows x 2 columns]\nMean Absolute Error: 2681.2430726638395\nMean Squared Error: 13246002.119140355\nRoot Mean Squared Error: 3639.505752041114\nR2 Score: 79.941657245098%\n\nTest Size: 20 %\n\na = -7307.824968281864\nb = [-522.31275964  128.16628088   63.17240963]\n     Actual     Predicted\n0    6795.0   6561.779408\n1   15750.0  20047.965597\n..      ...           ...\n39  45400.0  39099.945713\n40   8916.5   6559.957946\n\n[41 rows x 2 columns]\nMean Absolute Error: 3028.44528450474\nMean Squared Error: 15255724.671464592\nRoot Mean Squared Error: 3905.8577382522003\nR2 Score: 80.29392621688581%\n\nTest Size: 10 %\n\na = -7824.384102535303\nb = [-613.42877141  135.45474355   63.82356299]\n     Actual     Predicted\n0    6795.0   6388.284759\n1   15750.0  20259.732808\n..      ...           ...\n19   6488.0   6140.798124\n20   9959.0  12025.455910\n\n[21 rows x 2 columns]\nMean Absolute Error: 2944.3040595022885\nMean Squared Error: 12712894.325743863\nRoot Mean Squared Error: 3565.5145948016907\nR2 Score: 68.17562555579416%\n\n\n\n\n\n3.2.3 Carlength, Carwidth, Curbweight, Cylinder Number, Engine Size, Horsepower vs Price\n\n\nCode\n# Store carlength, carwidth, curbweight, cylindernumber,\n# enginesize & horsepower columns in X\nX3 = datasetCopy.iloc[:, 10:-4].values\n\n# Call Regression Model Function with multiple x values & 30% test size\nmyLinRegModel(X3, price, 30)\n\n\nTest Size: 30 %\n\na = -50133.27454870472\nb = [-62.20404054 772.47835707   3.18527494  18.99449375  65.77507898\n  64.33402142]\n     Actual     Predicted\n0    6795.0   6067.345502\n1   15750.0  20331.280734\n..      ...           ...\n60   6479.0   5548.422659\n61  15510.0  13525.755400\n\n[62 rows x 2 columns]\nMean Absolute Error: 2536.7293535638096\nMean Squared Error: 12555624.008739235\nRoot Mean Squared Error: 3543.39159686581\nR2 Score: 80.98709273909488%\n\nTest Size: 20 %\n\na = -54793.72590677004\nb = [-38.92156396 789.71920542   2.95208156 366.09875078  59.3369646\n  58.3182745 ]\n     Actual     Predicted\n0    6795.0   6167.243070\n1   15750.0  20562.635157\n..      ...           ...\n39  45400.0  36977.654082\n40   8916.5   5783.745608\n\n[41 rows x 2 columns]\nMean Absolute Error: 2873.7239149228203\nMean Squared Error: 16025434.859390952\nRoot Mean Squared Error: 4003.178094887979\nR2 Score: 79.29967874050975%\n\nTest Size: 10 %\n\na = -55531.82635570387\nb = [-30.01857827 784.53201154   2.29960226 213.59515415  74.83936968\n  58.2469381 ]\n     Actual     Predicted\n0    6795.0   6065.470340\n1   15750.0  20665.341927\n..      ...           ...\n19   6488.0   5585.072554\n20   9959.0  11876.766620\n\n[21 rows x 2 columns]\nMean Absolute Error: 3020.6881171033187\nMean Squared Error: 13605511.765351668\nRoot Mean Squared Error: 3688.5650008304947\nR2 Score: 65.94112325398689%"
  },
  {
    "objectID": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#no-scaling",
    "href": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#no-scaling",
    "title": "Linear Regression, Classification, Clustering",
    "section": "4.1 No Scaling",
    "text": "4.1 No Scaling\n\n\nCode\n# Store all numeric values in X\nX = dataset[['wheelbase', 'carlength', 'carwidth', 'carheight',\\\n             'curbweight', 'cylindernumber', 'enginesize', 'boreratio',\\\n             'stroke', 'compressionratio', 'horsepower', 'peakrpm',\\\n             'citympg', 'highwaympg', 'price']].values\n\n# Classify according to fuel type\ny = dataset['fueltype']\n\n# Call Classification Model Function with no scalar\nmyClassModel(X, y, 'None')\n\n\n\n\n\nKNeigbors Classifier - Scaling: None\n              precision    recall  f1-score   support\n\n      diesel       0.00      0.00      0.00         6\n         gas       0.85      0.94      0.89        35\n\n    accuracy                           0.80        41\n   macro avg       0.42      0.47      0.45        41\nweighted avg       0.72      0.80      0.76        41\n\nDecision Tree Classifier - Scaling: None\n              precision    recall  f1-score   support\n\n      diesel       1.00      1.00      1.00         6\n         gas       1.00      1.00      1.00        35\n\n    accuracy                           1.00        41\n   macro avg       1.00      1.00      1.00        41\nweighted avg       1.00      1.00      1.00        41\n\n\n\n\n\n\n\n\n(a) KNeigbors Classifier\n\n\n\n\n\n\n\n(b) Decision Tree Classifier\n\n\n\n\nFigure¬†5. Classifier Models Confusion Matrices - No Scaling"
  },
  {
    "objectID": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#standardized-scaling",
    "href": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#standardized-scaling",
    "title": "Linear Regression, Classification, Clustering",
    "section": "4.2 Standardized Scaling",
    "text": "4.2 Standardized Scaling\n\n\nCode\n# Store all numeric values in X\nX = dataset[['wheelbase', 'carlength', 'carwidth', 'carheight',\\\n             'curbweight', 'cylindernumber', 'enginesize', 'boreratio',\\\n             'stroke', 'compressionratio', 'horsepower', 'peakrpm',\\\n             'citympg', 'highwaympg', 'price']].values\n\n# Classify according to fuel type\ny = dataset['fueltype']\n\n# Call Classification Model Function with no scalar\nmyClassModel(X, y, 'Standardize')\n\n\n\n\n\nKNeigbors Classifier - Scaling: Standardize\n              precision    recall  f1-score   support\n\n      diesel       1.00      1.00      1.00         3\n         gas       1.00      1.00      1.00        38\n\n    accuracy                           1.00        41\n   macro avg       1.00      1.00      1.00        41\nweighted avg       1.00      1.00      1.00        41\n\nDecision Tree Classifier - Scaling: Standardize\n              precision    recall  f1-score   support\n\n      diesel       1.00      1.00      1.00         3\n         gas       1.00      1.00      1.00        38\n\n    accuracy                           1.00        41\n   macro avg       1.00      1.00      1.00        41\nweighted avg       1.00      1.00      1.00        41\n\n\n\n\n\n\n\n\n(a) KNeigbors Classifier\n\n\n\n\n\n\n\n(b) Decision Tree Classifier\n\n\n\n\nFigure¬†6. Classifier Models Confusion Matrices - Standard Scaling"
  },
  {
    "objectID": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#normalized-scaling",
    "href": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#normalized-scaling",
    "title": "Linear Regression, Classification, Clustering",
    "section": "4.3 Normalized Scaling",
    "text": "4.3 Normalized Scaling\n\n\nCode\n# Store all numeric values in X\nX = dataset[['wheelbase', 'carlength', 'carwidth', 'carheight',\\\n             'curbweight', 'cylindernumber', 'enginesize', 'boreratio',\\\n             'stroke', 'compressionratio', 'horsepower', 'peakrpm',\\\n             'citympg', 'highwaympg', 'price']].values\n\n# Classify according to fuel type\ny = dataset['fueltype']\n\n# Call Classification Model Function with no scalar\nmyClassModel(X, y, 'Normalize')\n\n\n\n\n\nKNeigbors Classifier - Scaling: Normalize\n              precision    recall  f1-score   support\n\n      diesel       1.00      1.00      1.00         3\n         gas       1.00      1.00      1.00        38\n\n    accuracy                           1.00        41\n   macro avg       1.00      1.00      1.00        41\nweighted avg       1.00      1.00      1.00        41\n\nDecision Tree Classifier - Scaling: Normalize\n              precision    recall  f1-score   support\n\n      diesel       1.00      1.00      1.00         3\n         gas       1.00      1.00      1.00        38\n\n    accuracy                           1.00        41\n   macro avg       1.00      1.00      1.00        41\nweighted avg       1.00      1.00      1.00        41\n\n\n\n\n\n\n\n\n(a) KNeigbors Classifier\n\n\n\n\n\n\n\n(b) Decision Tree Classifier\n\n\n\n\nFigure¬†7. Classifier Models Confusion Matrices - Normalized Scaling"
  },
  {
    "objectID": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#kmeans-model",
    "href": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#kmeans-model",
    "title": "Linear Regression, Classification, Clustering",
    "section": "5.1 KMeans Model",
    "text": "5.1 KMeans Model\n\n\nCode\n# Store all features in X\nX = dataset[['compressionratio', 'price']]\n\n# KMeans Cluster Model to be used\nmodel = 'KM'\n\n# Number of clusters to be created\nn_clusters = 3\n\n# Call Clustering Model Function and pass in features\n# model & number of clusters\nmyClusterModel(X, model, n_clusters)\n\n\n\n\n\n\n\n\n(a) Scatter Plot - No Scaling\n\n\n\n\n\n\n\n(b) Joint Plot - No Scaling\n\n\n\n\n\n\n\n\n\n(c) Joint Plot - Normalized Scaling\n\n\n\n\nFigure¬†8. KMeans Cluster Model Visualizations"
  },
  {
    "objectID": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#gaussian-mixture-model",
    "href": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#gaussian-mixture-model",
    "title": "Linear Regression, Classification, Clustering",
    "section": "5.2 Gaussian Mixture Model",
    "text": "5.2 Gaussian Mixture Model\n\n\nCode\n# Store all features in X\nX = dataset[['compressionratio', 'price']]\n\n# Gaussian Mixture Model to be used\nmodel = 'GMM'\n\n# Number of clusters to be created\nn_clusters = 3\n\n# Call Clustering Model Function and pass in features\n# model & number of clusters\nmyClusterModel(X, model, n_clusters)\n\n\n\n\n\n\n\n\n(a) Joint Plot - No Scaling\n\n\n\n\n\n\n\n(b) Joint Plot - Normalized Scaling\n\n\n\n\nFigure¬†9. Gaussian Mixture Cluster Model Visualizations"
  },
  {
    "objectID": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#spectral-clustering-model",
    "href": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#spectral-clustering-model",
    "title": "Linear Regression, Classification, Clustering",
    "section": "5.3 Spectral Clustering Model",
    "text": "5.3 Spectral Clustering Model\n\n\nCode\n# Store all features in X\nX = dataset[['compressionratio', 'price']]\n\n# Spectral Clustering Model to be used\nmodel = 'SC'\n\n# Number of clusters to be created\nn_clusters = 3\n\n# Call Clustering Model Function and pass in features\n# model & number of clusters\nmyClusterModel(X, model, n_clusters)\n\n\n\n\n\n\n\n\n(a) Joint Plot - No Scaling\n\n\n\n\n\n\n\n(b) Joint Plot - Normalized Scaling\n\n\n\n\nFigure¬†10. Spectral Clustering Model Visualizations"
  },
  {
    "objectID": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#references",
    "href": "posts/intro-to-ai-assignment1/Assignment1BrandonToews.html#references",
    "title": "Linear Regression, Classification, Clustering",
    "section": "References",
    "text": "References\nDataset\nhttps://www.kaggle.com/datasets/hellbuoy/car-price-prediction?select=CarPrice_Assignment.csv\nData Cleaning\nhttps://datatofish.com/category/python/\nData Scaling\nhttps://dataakkadian.medium.com/standardization-vs-normalization-da7a3a308c64\nhttps://medium.datadriveninvestor.com/data-pre-processing-with-scikit-learn-9896c561ef2f\nMeasuring Accuracy\nhttps://www.bmc.com/blogs/mean-squared-error-r2-and-variance-in-regression-analysis/\nVisualizations\nhttps://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html\nhttps://seaborn.pydata.org/api.html\nhttps://matplotlib.org/stable/api/pyplot_summary.html\nClassification & Clustering Models\nhttps://www.activestate.com/resources/quick-reads/how-to-classify-data-in-python/\nhttps://builtin.com/data-science/data-clustering-python\nhttps://towardsdatascience.com/machine-learning-algorithms-part-9-k-means-example-in-python-f2ad05ed5203\nGeneral Python\nhttps://stackoverflow.com"
  },
  {
    "objectID": "posts/star-map-nav/star-map-nav.html",
    "href": "posts/star-map-nav/star-map-nav.html",
    "title": "Star Map Navigation Simulation",
    "section": "",
    "text": "Play Demo\n\n\n\n\n\n\nCamera Keyboard Controls\n\n\n\n\n\n\n\n\nForward\nUp Arrow or W\nDown\nQ\n\n\nBackward\nDown Arrow or S\nLook Left\nZ\n\n\nStrafe Left\nLeft Arrow or A\nLook Right\nX\n\n\nStrafe Right\nRight Arrow or D\nLook Up\nR\n\n\nUp\nE\nLook Down\nF\n\n\nEscape Program\nEsc\nReset Galaxy\nSpace\n\n\n\nInstructions\nUse the camera controls to look around the generated galaxy and use the mouse to select stars by clicking on them. When two stars have been selected the shortest path between them is drawn and the path/distances are displayed to the user in the UI. To deselect stars click on anything that isn‚Äôt a star. Press Space to regenerate a new galaxy.\n\nüöÄ Play Demo\n\n\n\n\n\nStar Map Navigation Simulation\nProject to implement a star map navigation style simulation using the Unity Games Engine all written in C#. Mathematical programming techniques were used to craft a custom pathfinding djikstra script to chart shortest path from user selected stars. I created custom math methods to perform various calculations involving matrices and incorporated custom lerp libraries and UI scripts from my previous Modes of Motion Unity project.\n\n\n\n\n\n\nSource Code\n\n\n\nView source code on Github repository.\n\n\n\n\nVideo Walkthrough\nVideo"
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#purpose-of-document",
    "href": "posts/linux-admin/linux-admin.html#purpose-of-document",
    "title": "Linux Administration Project",
    "section": "1.1 Purpose of Document",
    "text": "1.1 Purpose of Document\nThe purpose of this document is to provide suggestions, solutions, and configurations for a major upgrade that will improve the current network."
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#scope",
    "href": "posts/linux-admin/linux-admin.html#scope",
    "title": "Linux Administration Project",
    "section": "1.2 Scope",
    "text": "1.2 Scope\nThe scope of the project involves an examination of the current network to ascertain where it can be improved. In addition, design and implemention of a prototype network to demonstrate what it could look like after the proposed upgrades. The proposed solutions must include detailed configurations and address potential growth of the business in the future."
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#existing-network-design",
    "href": "posts/linux-admin/linux-admin.html#existing-network-design",
    "title": "Linux Administration Project",
    "section": "2.1 Existing Network Design",
    "text": "2.1 Existing Network Design\nThe existing network utilizes 11 servers comprised of one (1) NIS authentication server, two (2) NFS file share servers, one (1) Telnet server, two (2) database servers, two (2) app servers, two (2) web servers, and one (1) backup server. ( See Figure¬†1 )\n\n\n\nFigure¬†1. Existing Network Topology"
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#proposed-network-topology",
    "href": "posts/linux-admin/linux-admin.html#proposed-network-topology",
    "title": "Linux Administration Project",
    "section": "2.2 Proposed Network Topology",
    "text": "2.2 Proposed Network Topology\nThe proposed network utilizes 11 servers comprised of one (1) LDAP authentication server, one (1) Samba file share server, one (1) NFS file share server, two (2) database servers, two (2) app servers, two (2) web servers, one (1) backup server, and one (1) Firewall. ( See Figure¬†2 )\n\n\n\nFigure¬†2. Proposed Network Topology"
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#server-os-upgrade",
    "href": "posts/linux-admin/linux-admin.html#server-os-upgrade",
    "title": "Linux Administration Project",
    "section": "3.1 Server OS Upgrade",
    "text": "3.1 Server OS Upgrade\nThe existing servers are all running CentOS 5.0 currently which is starting to become old and losing community support. All servers should be upgraded to CentOS 7.0 as this will provide the most support while maintaining stronger stability that newer releases.3.2 LDAP Centralized Authentication Current network athentication is managed by a NIS server which only functions for Linux operating systems and passes sensitive information in plain text. The prototype network runs an LDAP server instead for many reasons. Eventually the Windows clients can be looped into the system to authenticate making it so that the total Linux and Windows structures would all be managed from the same place. In addition LDAP touts improved security as it utilizes TLS certifications to establish connections and pass information. The LDAP server can be used to authenticate against for all of the other services that the network contains."
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#firewall-addition",
    "href": "posts/linux-admin/linux-admin.html#firewall-addition",
    "title": "Linux Administration Project",
    "section": "3.2 Firewall Addition",
    "text": "3.2 Firewall Addition\nNo firewall is present with the existing network which places the system at significantly more risk. With the addition of a pfSense firewall in place all internal traffic is protected and blocked from the external. All traffic that accesses anything outside of the LAN, including and especially the internet, is routed through firewall so as to keep as small of an attack surface as possible."
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#samba-share-server",
    "href": "posts/linux-admin/linux-admin.html#samba-share-server",
    "title": "Linux Administration Project",
    "section": "3.3 Samba Share Server",
    "text": "3.3 Samba Share Server\nWhile the two (2) NFS share servers are useful they are overkill and could be downsized to make room for something that may grow better with the company in the future. One (1) of the NFS servers has been replaced in the prototype network for a Samba server. At the moment the Samba server is just acting as a share but the possibilities for it to be so much more are endless. In the future it could be utilized alongside the LDAP server to provide authentication for both Windows and Linux clients. All users could sign in on whatever device they prefer while the Samba server acts as an NT4 primary domain server or even an Active Directory domain controller, all with an LDAP backend. This would all for a possibility to add a secondary domain server to add redundancy to the system and provide stability as the business grows."
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#telnet-ftp",
    "href": "posts/linux-admin/linux-admin.html#telnet-ftp",
    "title": "Linux Administration Project",
    "section": "3.4 Telnet & FTP",
    "text": "3.4 Telnet & FTP\nThe current system utilizes Telnet for communications among servers which has been long recognized as very insecure and should not be used in production. Hence all Telnet services have been replaced with SSH servers so as to secure and encrypted communications. Having SSH servers allows us to take advantage of Secure Copy Protocol which will also replace the very insecure File Transfer Protocol servers the occupy the system now. Neither Telnet nor FTP servers should be used as long as we have better options like SSH and SCP available to us."
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#ldap-configuration",
    "href": "posts/linux-admin/linux-admin.html#ldap-configuration",
    "title": "Linux Administration Project",
    "section": "4.1 LDAP Configuration",
    "text": "4.1 LDAP Configuration\nThe LDAP server has an NFS server running on it to export the home directories to the client servers so that they can automount them when they login to various users. The LDAP structure has been generated on the LDAP server using the following ldif files and ens33 file‚Ä¶ db.ldif, monitor.ldif, base.ldif, users.ldif, groups.ldif, ens33.\n\n\ndb.ldif\n\ndn: olcDatabase={2}hdb,cn=config\nchangetype: modify\nreplace: olcSuffix\nolcSuffix: dc=azuretech,dc=local\n\ndn: olcDatabase={2}hdb,cn=config\nchangetype: modify\nreplace: olcRootDN\nolcRootDN: cn=ldapadm,dc=azuretech,dc=local\n\ndn: olcDatabase={2}hdb,cn=config\nchangetype: modify\nreplace: olcRootPW\nolcRootPW: {SSHA}GBlGYcFck5dRl6+FwVlArdlJywiCsCfK\n\n\n\nmonitor.ldif\n\ndn: olcDatabase={1}monitor,cn=config\nchangetype: modify\nreplace: olcAccess\nolcAccess: {0}to * by dn.base=\"gidNumber=0+uidNumber=0,cn=peercred,cn=external,\ncn=auth\" read by dn.base=\"cn=ldapadm,dc=azuretech,dc=local\" read by * none\n\n\n\nbase.ldif\n\ndn: dc=azuretech,dc=local\ndc: azuretech\nobjectClass: top\nobjectClass: domain\n\ndn: cn=ldapadm,dc=azuretech,dc=local\nobjectClass: organizationalRole\ncn: ldapadm\ndescription: LDAP Manager\n\ndn: ou=People,dc=azuretech,dc=local\nobjectClass: organizationalUnit\nou: People\n\ndn: ou=Group,dc=azuretech,dc=local\nobjectClass: organizationalUnit\nou: Group\n\n\n\nusers.ldif\n\ndn: uid=ldapuser1,ou=People,dc=azuretech,dc=local\nuid: ldapuser1\ncn: ldapuser1\nsn: ldapuser1\nmail: ldapuser1@azuretech.local\nobjectClass: person\nobjectClass: organizationalPerson\nobjectClass: inetOrgPerson\nobjectClass: posixAccount\nobjectClass: topobjectClass: shadowAccount\nuserPassword:\n{crypt}\n$6$SCUZRM.D$B4l.n2hipD4IvghGaaJiQtLkiOF62YS7PhDy30EpVd81noq4KkDU2EqORUW.\n8Dq4k5GhPkChklxZIYiKMvcFx1\nshadowLastChange: 19159\nshadowMin: 0\nshadowMax: 99999\nshadowWarning: 7\nloginShell: /bin/bash\nuidNumber: 1000\ngidNumber: 1000\nhomeDirectory: /home/ldapuser1\n\ndn: uid=ldapuser2,ou=People,dc=azuretech,dc=local\nuid: ldapuser2\ncn: ldapuser2\nsn: ldapuser2\nmail: ldapuser2@azuretech.local\nobjectClass: person\nobjectClass: organizationalPerson\nobjectClass: inetOrgPerson\nobjectClass: posixAccount\nobjectClass: top\nobjectClass: shadowAccount\nuserPassword:\n{crypt}\n$6$CbncYy5y$JlNL4899lmlZAgqnLYersesFTLkFJNY6DQdNvwOFU8LyHNXPMMrfCaUo7Br\nSdYw/KFlDOubpyn2b242re1Zea/\nshadowLastChange: 19159\nshadowMin: 0\nshadowMax: 99999\nshadowWarning: 7\nloginShell: /bin/bash\nuidNumber: 1001gidNumber: 1001\nhomeDirectory: /home/ldapuser2\n\ndn: uid=ldapuser3,ou=People,dc=azuretech,dc=local\nuid: ldapuser3\ncn: ldapuser3\nsn: ldapuser3\nmail: ldapuser3@azuretech.local\nobjectClass: person\nobjectClass: organizationalPerson\nobjectClass: inetOrgPerson\nobjectClass: posixAccount\nobjectClass: top\nobjectClass: shadowAccount\nuserPassword:\n{crypt}\n$6$J5mrmTYw$bKruVOsucaiHJFS3S6MKG4jyC.o/P62DeLW/R.YVpktFaYlpHzjjjxIGW5HpA\nmsf5OCN9dId5s/F33HptMfvG0\nshadowLastChange: 19159\nshadowMin: 0\nshadowMax: 99999\nshadowWarning: 7\nloginShell: /bin/bash\nuidNumber: 1002\ngidNumber: 1002\nhomeDirectory: /home/ldapuser3\n\n\n\ngroups.ldif\n\ndn: cn=ldapuser1,ou=Group,dc=azuretech,dc=local\nobjectClass: posixGroup\nobjectClass: top\ncn: ldapuser1\nuserPassword: {crypt}x\ngidNumber: 1000\n\ndn: cn=ldapuser2,ou=Group,dc=azuretech,dc=local\nobjectClass: posixGroup\nobjectClass: top\ncn: ldapuser2\nuserPassword: {crypt}x\ngidNumber: 1001\n\ndn: cn=ldapuser3,ou=Group,dc=azuretech,dc=local\nobjectClass: posixGroup\nobjectClass: top\ncn: ldapuser3\nuserPassword: {crypt}x\ngidNumber: 1002\n\n\n\n/etc/sysconfig/network-scripts/ifcfg-ens33\n\nTYPE=\"Ethernet\"\nPROXY_METHOD=\"none\"\nBROWSER_ONLY=\"no\"\nBOOTPROTO=\"none\"\nDEFROUTE=\"yes\"\nIPV4_FAILURE_FATAL=\"no\"\nIPV6INIT=\"no\"\n#IPV6_AUTOCONF=\"yes\"\n#IPV6_DEFROUTE=\"yes\"\n#IPV6_FAILURE_FATAL=\"no\"\n#IPV6_ADDR_GEN_MODE=\"stable-privacy\"\nNAME=\"ens33\"\nUUID=\"93f56d12-8057-4ca0-af7f-6c8e6fcffccd\"\nDEVICE=\"ens33\"\nONBOOT=\"yes\"\nIPADDR=\"192.168.65.10\"\nPREFIX=\"24\"\nGATEWAY=\"192.168.65.20\"\nDNS1=\"192.168.65.10\"\nDNS2=\"8.8.8.8\"\nDNS3=\"8.8.4.4\"\nDOMAIN=\"azuretech.local\""
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#ldap-client-configuration",
    "href": "posts/linux-admin/linux-admin.html#ldap-client-configuration",
    "title": "Linux Administration Project",
    "section": "4.2 LDAP Client Configuration",
    "text": "4.2 LDAP Client Configuration\nThe LDAP Clients need to install some packing and create some automap files for autofs to automount LDAP user home directories. I used the follow script to accomplish this‚Ä¶\n\n\nLDAP_Client_Install.sh\n\n#!/bin/bash\nyum install -y openldap-clients nss-pam-ldapd nfs-utils autofs\nauthconfig --enableldap --enableldapauth --ldapserver=192.168.65.10 --ldapbasedn=\"dc=azuretech,dc=local\" --update\nsystemctl restart nslcd\nsetsebool -P use_nfs_home_dirs=1\necho \"/home /etc/home.map\" &gt;&gt; /etc/auto.master\necho \"* -fstype=nfs,rw,nosuid,soft 192.168.65.10:/home/&\" &gt;&gt; /etc/home.map\nsystemctl enable rpcbind\nsystemctl start rpcbind\nsystemctl enable autofs\nsystemctl start autofs\nexit"
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#firewall-configuration",
    "href": "posts/linux-admin/linux-admin.html#firewall-configuration",
    "title": "Linux Administration Project",
    "section": "4.3 Firewall Configuration",
    "text": "4.3 Firewall Configuration\nConfigured as seen in figures below. ( See Figure¬†3, Figure¬†4, & Figure¬†5)\n\n\n\nFigure¬†3. Firewall Configurations\n\n\n\n\n\nFigure¬†4. Firewall Configurations\n\n\n\n\n\nFigure¬†5. Firewall Configurations"
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#dns-master-server-configuration",
    "href": "posts/linux-admin/linux-admin.html#dns-master-server-configuration",
    "title": "Linux Administration Project",
    "section": "4.4 DNS Master Server Configuration",
    "text": "4.4 DNS Master Server Configuration\nThe DNS master server was installed on the same server as the LDAP so it is referred to as LDAP in the configuration files. The main config, the forward zone, and the reverse zone files shown below‚Ä¶\n\n\n/etc/named.conf\n\n//\n// named.conf\n//\n// Provided by Red Hat bind package to configure the ISC BIND named(8) DNS\n// server as a caching only nameserver (as a localhost DNS resolver only).\n//\n// See /usr/share/doc/bind*/sample/ for example named configuration files.\n//\n// See the BIND Administrator's Reference Manual (ARM) for details about the\n// configuration located in /usr/share/doc/bind-{version}/Bv9ARM.html\n\noptions {\n  listen-on port 53 { 127.0.0.1; 192.168.65.10; };\n  // listen-on-v6 port 53 { ::1; };\n  directory\"/var/named\";\n  dump-file\"/var/named/data/cache_dump.db\";\n  statistics-file \"/var/named/data/named_stats.txt\";\n  memstatistics-file \"/var/named/data/named_mem_stats.txt\";\n  recursing-file \"/var/named/data/named.recursing\";\n  secroots-file \"/var/named/data/named.secroots\";\n  allow-query    { localhost; 192.168.65.0/24; };\n  allow-transfer { localhost; 192.168.65.11; };\n  \n  /*\n    - If you are building an AUTHORITATIVE DNS server, do NOT enable recursion.\n    - If you are building a RECURSIVE (caching) DNS server, you need to enable\n      recursion.\n    - If your recursive DNS server has a public IP address, you MUST enable access\n      control to limit queries to your legitimate users. Failing to do so will\n      cause your server to become part of large scale DNS amplification\n      attacks. Implementing BCP38 within your network would greatly\n      reduce such attack surface\n  */\n  recursion no;\n  \n  dnssec-enable yes;\n  dnssec-validation yes;\n  // dnssec-lookaside auto;\n  \n  /* Path to ISC DLV key */\n  bindkeys-file \"/etc/named.root.key\";managed-keys-directory \"/var/named/dynamic\";\n  \n  pid-file \"/run/named/named.pid\";\n  session-keyfile \"/run/named/session.key\";\n};\n\nlogging {\n  channel default_debug {\n    file \"data/named.run\";\n    severity dynamic;\n  };\n};\n\nzone \".\" IN {\n  type hint;\n  file \"named.ca\";\n};\n\nzone \"azuretech.local\" IN {\n  type master;\n  file \"forward.azuretech\";\n  allow-update { none; };\n};\n\nzone \"65.168.192.in-addr.arpa\" IN {\n  type master;\n  file \"reverse.azuretech\";\n  allow-update { none; };\n};\n\ninclude \"/etc/named.rfc1912.zones\";\ninclude \"/etc/named.root.key\";\n\n\n\n/var/named/forward.azuretech\n\n$TTL 86400\n@   IN SOA ldap.azuretech.local. root.azuretech.local. (\n                    2022061101 ; serial\n                    3600; refresh\n                    1800; retry\n                    604800 ; expire\n                    86400 ) ; minimum TTL\n                    \n;Name Servers\n    IN    NS    ldap.azuretech.local.     ; Master\n    IN    NS    samba.azuretech.local.    ; Slave\n  \n    IN    A     192.168.65.10 ; Name Server to IP resolve\n    IN    A     192.168.65.11\n  \nldap        IN    A   192.168.65.10 ; Host\nsamba       IN    A   192.168.65.11 ; Host\nnfs         IN    A   192.168.65.12 ; Client\nbackup      IN    A   192.168.65.13 ; Client\ndb1         IN    A   192.168.65.14 ; Client\ndb2         IN    A   192.168.65.15 ; Client\napp1        IN    A   192.168.65.16 ; Client\napp2        IN    A   192.168.65.17 ; Client\nweb1        IN    A   192.168.65.18 ; Client\nweb2        IN    A   192.168.65.19 ; Client\nfirewall    IN    A   192.168.65.20 ; Firewall\n\n\n\n/var/named/reverse.azuretech\n\n$TTL 86400\n@   IN SOA ldap.azuretech.local. root.azuretech.local. (\n                    2022061101 ; serial\n                    3600; refresh\n                    1800; retry\n                    604800 ; expire\n                    86400 ) ; minimum TTL\n                    \n;Name Servers\n    IN    NS    ldap.azuretech.local.   ; Master\n    IN    NS    samba.azuretech.local.  ; Slave\n    IN    PTR   azuretech.local.\n    \n;Record (IP) points to hostname\nldap        IN    A   192.168.65.10 ; Master Nameserver\nsamba       IN    A   192.168.65.11 ; Slave Nameserver\nnfs         IN    A   192.168.65.12 ; Client\nbackup      IN    A   192.168.65.13 ; Client\ndb1         IN    A   192.168.65.14 ; Client\ndb2         IN    A   192.168.65.15 ; Client\napp1        IN    A   192.168.65.16 ; Client\napp2        IN    A   192.168.65.17 ; Client\nweb1        IN    A   192.168.65.18 ; Client\nweb2        IN    A   192.168.65.19 ; Client\nfirewall    IN    A   192.168.65.20 ; Firewall\n\n10    IN    PTR   ldap.azuretech.local.\n11    IN    PTR   samba.azuretech.local.\n12    IN    PTR   nfs.azuretech.local.\n13    IN    PTR   backup.azuretech.local.\n14    IN    PTR   db1.azuretech.local.\n15    IN    PTR   db2.azuretech.local.\n16    IN    PTR   app1.azuretech.local.\n17    IN    PTR   app2.azuretech.local.\n18    IN    PTR   web1.azuretech.local.\n19    IN    PTR   web2.azuretech.local.\n20    IN    PTR   firewall.azuretech.local."
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#dns-slave-server-configuration",
    "href": "posts/linux-admin/linux-admin.html#dns-slave-server-configuration",
    "title": "Linux Administration Project",
    "section": "4.5 DNS Slave Server Configuration",
    "text": "4.5 DNS Slave Server Configuration\nThe DNS slave server was installed on the same server as the Samba, so it is referred to as samba in the configuration files. The main config file is shown below‚Ä¶\n\n\n/etc/name.conf\n\n//\n// named.conf\n//\n// Provided by Red Hat bind package to configure the ISC BIND named(8) DNS\n// server as a caching only nameserver (as a localhost DNS resolver only).\n//\n// See /usr/share/doc/bind*/sample/ for example named configuration files.\n//\n// See the BIND Administrator's Reference Manual (ARM) for details about the\n// configuration located in /usr/share/doc/bind-{version}/Bv9ARM.html\n\noptions {\n  listen-on port 53 { 127.0.0.1; 192.168.65.11; };\n  // listen-on-v6 port 53 { ::1; };\n  directory\"/var/named\";\n  dump-file\"/var/named/data/cache_dump.db\";\n  statistics-file \"/var/named/data/named_stats.txt\";\n  memstatistics-file \"/var/named/data/named_mem_stats.txt\";\n  recursing-file \"/var/named/data/named.recursing\";\n  secroots-file \"/var/named/data/named.secroots\";\n  allow-query { localhost; 192.168.65.0/24; };\n  \n  /*\n    - If you are building an AUTHORITATIVE DNS server, do NOT enable recursion.\n    - If you are building a RECURSIVE (caching) DNS server, you need to enable\n      recursion.\n    - If your recursive DNS server has a public IP address, you MUST enable access\n      control to limit queries to your legitimate users. Failing to do so will\n      cause your server to become part of large scale DNS amplification\n      attacks. Implementing BCP38 within your network would greatly\n      reduce such attack surface\n  */\n  recursion no;\n\n  dnssec-enable yes;\n  dnssec-validation yes;\n\n  /* Path to ISC DLV key */\n  bindkeys-file \"/etc/named.root.key\";\n\n  managed-keys-directory \"/var/named/dynamic\";\n\n  pid-file \"/run/named/named.pid\";\n  session-keyfile \"/run/named/session.key\";\n};\n\nlogging {\n  channel default_debug {\n    file \"data/named.run\";\n    severity dynamic;\n  };\n};\n\nzone \".\" IN {\n  type hint;\n  file \"named.ca\";\n};\n\nzone \"azuretech.local\" IN {\n  type slave;\n  file \"slaves/azuretech.fwd.zone\";\n  masters { 192.168.65.10; };\n};\n\nzone \"65.168.192.in-addr.arpa\" IN {\n  type slave;\n  file \"slaves/azuretech.rev.zone\";\n  masters { 192.168.65.10; };\n};\n\ninclude \"/etc/named.rfc1912.zones\";\ninclude \"/etc/named.root.key\";"
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#dhcp-server-configuration",
    "href": "posts/linux-admin/linux-admin.html#dhcp-server-configuration",
    "title": "Linux Administration Project",
    "section": "4.6 DHCP Server Configuration",
    "text": "4.6 DHCP Server Configuration\nThe DHCP server was installed on the same server as the LDAP. The main config file is shown below‚Ä¶\n\n\n/etc/dhcp/dhcpd.conf\n\n#\n# DHCP Server Configuration file.# see /usr/share/doc/dhcp*/dhcpd.conf.example\n# see dhcpd.conf(5) man page\n#\noption domain-name \"azuretech.local\";\noption domain-name-servers ldap.azuretech.local, samba.azuretech.local, 8.8.8.8, 8.8.4.4;\n\ndefault-lease-time 86400; # 24 hours\nmax-lease-time 604800;    # One week\n\n# Use this to enble / disable dynamic dns updates globally.\n#ddns-update-style none;\n\n# If this DHCP server is the official DHCP server for the local\n# network, the authoritative directive should be uncommented.\nauthoritative;\n\nsubnet 192.168.65.0 netmask 255.255.255.0 {\n  range 192.168.65.21 192.168.65.100;\n  option domain-name-servers 192.168.65.10, 192.168.65.11, 8.8.8.8, 8.8.4.4;\n  option domain-name \"azuretech.local\";\n  option routers 192.168.65.2;\n  option subnet-mask 255.255.255.0;\n  option broadcast-address 192.168.65.255;\n}\n\nhost nfs {\n  hardware ethernet 00:0c:29:08:dc:1c;\n  fixed-address 192.168.65.12;\n}\n\nhost backup {\n  hardware ethernet 00:0c:29:0e:59:b4;\n  fixed-address 192.168.65.13;\n}\n\nhost db1 {\n  hardware ethernet 00:0c:29:d1:f5:0c;\n  fixed-address 192.168.65.14;\n}\n\nhost db2 {\n  hardware ethernet 00:0c:29:95:46:a9;\n  fixed-address 192.168.65.15;\n}\nhost app1 {\n  hardware ethernet 00:0c:29:83:8c:60;\n  fixed-address 192.168.65.16;\n}\n\nhost app2 {\n  hardware ethernet 00:0c:29:f2:40:5c;\n  fixed-address 192.168.65.17;\n}\n\nhost web1 {\n  hardware ethernet 00:0c:29:a7:d9:38;\n  fixed-address 192.168.65.18;\n}\n\nhost web2 {\n  hardware ethernet 00:0c:29:e9:fa:2b;\n  fixed-address 192.168.65.19;\n}"
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#nfs-server-configuration",
    "href": "posts/linux-admin/linux-admin.html#nfs-server-configuration",
    "title": "Linux Administration Project",
    "section": "4.7 NFS Server Configuration",
    "text": "4.7 NFS Server Configuration\nThe NFS server‚Äôs export file and client fstab config file are shown below‚Ä¶\n\n\n/etc/exports\n\n/nfsfileshare 192.168.65.0/24(rw,sync,no_root_squash)\n\n\n\n/etc/fstab\n\n#\n# /etc/fstab\n# Created by anaconda on Wed May 11 18:06:18 2022\n#\n# Accessible filesystems, by reference, are maintained under '/dev/disk'\n# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info\n#\n/dev/mapper/centos-root /       xfs   defaults    00\nUUID=747f3e8d-9501-43e8-9ed3-3fae6fea9f23 /boot       xfs   defaults    00\n/dev/mapper/centos-swap swap        swap  defaults    00\nnfs:/nfsfileshare /mnt/nfsfileshare       nfs   nosuid,rw,sync,hard,intr    00"
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#samba-server-configuration",
    "href": "posts/linux-admin/linux-admin.html#samba-server-configuration",
    "title": "Linux Administration Project",
    "section": "4.8 Samba Server Configuration",
    "text": "4.8 Samba Server Configuration\nThe Samba server‚Äôs interface config and smb.conf files are shown below‚Ä¶\n\n\n/etc/sysconfig/network-scripts/ifcfg-ens33\n\nTYPE=\"Ethernet\"\nPROXY_METHOD=\"none\"\nBROWSER_ONLY=\"no\"\nBOOTPROTO=\"none\"\nDEFROUTE=\"yes\"\nIPV4_FAILURE_FATAL=\"no\"\nIPV6INIT=\"no\"\n#IPV6_AUTOCONF=\"yes\"\n#IPV6_DEFROUTE=\"yes\"\n#IPV6_FAILURE_FATAL=\"no\"\n#IPV6_ADDR_GEN_MODE=\"stable-privacy\"\nNAME=\"ens33\"\nUUID=\"eb0d3098-d1cd-4d11-9e74-e7478d56b0c5\"\nDEVICE=\"ens33\"\nONBOOT=\"yes\"\nIPADDR=\"192.168.65.11\"\nPREFIX=\"24\"\nGATEWAY=\"192.168.65.20\"\nDNS1=\"192.168.65.10\"\nDNS2=\"192.168.65.11\"\nDNS3=\"8.8.8.8\"\nDNS4=\"8.8.4.4\"\nDOMAIN=\"azuretech.local\"\n\n\n\n/etc/samba/smb.conf\n\n# See smb.conf.example for a more detailed config file or\n# read the smb.conf manpage.\n# Run 'testparm' to verify the config is correct after\n# you modified it.\n\n[global]\n  workgroup = SAMBA\n  security = user\n  \n  passdb backend = tdbsam\n  printing = cups\n  printcap name = cups\n  load printers = yes\n  cups options = raw\n\n[homes]\n  comment = Home Directories\n  valid users = %S, %D%w%S\n  browseable = No\n  read only = No\n  inherit acls = Yes\n\n[printers]\n  comment = All Printers\n  path = /var/tmp\n  printable = Yes\n  create mask = 0600\n  browseable = No\n\n[print$]\n  comment = Printer Drivers\n  path = /var/lib/samba/drivers\n  write list = @printadmin root\n  force group = @printadmin\n  create mask = 0664\n  directory mask = 0775\n\n[smb]\n  path = /samba\n  browseable = yes\n  read only = no\n  force create mode = 0660\n  force directory mode = 2770\n  valid users = smb @sadmin"
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#email-server-configuration",
    "href": "posts/linux-admin/linux-admin.html#email-server-configuration",
    "title": "Linux Administration Project",
    "section": "4.9 Email Server Configuration",
    "text": "4.9 Email Server Configuration\nThe email servers‚Äô were installed on the samba server machine and that is why it is labelled as samba in the config files. The Postfix and Dovecot config file alterations are shown below‚Ä¶\n\n\n/etc/postfix/main.cf\n\n# line 75: uncomment and specify hostname\nmyhostname = samba.azuretech.local\n\n# line 83: uncomment and specify domain name\nmydomain = azuretech.local\n\n# line 99: uncomment\nmyorigin = $mydomain\n\n# line 116: change\ninet_interfaces = all\n\n# line 164: add\nmydestination = $myhostname, localhost.$mydomain, localhost, $mydomain\n\n# line 264: uncomment and specify your local network\nmynetworks = 192.168.65.0/24\n\n# line 419: uncomment (use Maildir)\nhome_mailbox = Maildir/\n\n# line 574: add\nsmtpd_banner = $myhostname ESMTP\n\n# add follows to the end\n# limit an email size with 10M\nmessage_size_limit = 10485760\n\n\n\n/etc/dovecot/dovecot.conf\n\n# line 24: uncomment\nprotocols = imap pop3 lmtp\n\n# line 30: uncomment and change ( if not use IPv6 )\nlisten = *\n\n\n\n/etc/dovecot/conf.d/10-auth.conf\n\n# line 10: uncomment and change ( allow plain text auth )\ndisable_plaintext_auth = no\n\n# line 100: add\nauth_mechanisms = plain login\n\n\n\n/etc/dovecot/conf.d/10-mail.conf\n\n# line 30: uncomment and add\nmail_location = maildir:~/Maildir\n\n\n\n/etc/dovecot/conf.d/10-master.conf\n\n# line 96-98: uncomment and add like follows\n# Postfix smtp-auth\nunix_listener /var/spool/postfix/private/auth {\n  mode = 0666\n  user = postfix\n  group = postfix\n}\n\n\n\n/etc/dovecot/conf.d/10-ssl.conf\n\n# line 8: change (not require SSL)\nssl = no"
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#password-generator-script",
    "href": "posts/linux-admin/linux-admin.html#password-generator-script",
    "title": "Linux Administration Project",
    "section": "5.1 Password Generator Script",
    "text": "5.1 Password Generator Script\nAs an administration tool I created a random password generator script that asks how long you want the password to be. After it generates the password is asks if the user wants to output it into a file and if so, what should the file name be. The bash script code for the file is below‚Ä¶\n\n\npasswdgen_script.sh\n\n#!/bin/bash\n#This is a script for generating secure random password suggestions for users\necho -e \"\\n****** Secure Random Password Generator ******\\n\\nLet's generate a random password...\\n\\nHow long would you like your password to be?\\n\\nCharacter Length: \"\nread length\npasswd=`echo $RANDOM | md5sum | head -c ${length}`\necho -e \"\\nPassword Suggestion: ${passwd}\\n\\nWould you like to store this password in a file? (y/n): \"\nanswer=null\nwhile [ ${answer} != y ] || [ ${answer} != n ]; do\nread answer\nif [ ${answer} = \"y\" ]; then\n  echo -e \"\\nWhat would you like you filename to be?: \"\n  read filenm\n  echo ${passwd} &gt; ${filenm}\n  echo -e \"\\nFile has been saved in the current working directory... Goodbye!\\n\"\n  return\nelif [ ${answer} = \"n\" ]; then\n  echo -e \"\\nOk... Gooodbye!\\n\"\n  return\nelse\n  echo -e \"\\nNot a valid answer, try again.. You must choose either (y/n): \\r\"\nfi\ndone\nreturn"
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#ip-address-script",
    "href": "posts/linux-admin/linux-admin.html#ip-address-script",
    "title": "Linux Administration Project",
    "section": "5.2 IP Address Script",
    "text": "5.2 IP Address Script\nAs an administration tool I created an IP address script that asks you for an IP address. Then it asks the user for the subnet mask in bits and after which it prints the given IP address‚Äô classification along with the subnet mask in decimal format. Thoughout the script if the user gives the wrong output it tells the user what they did wrong and lets them try the input again. The bash script code for the file is below‚Ä¶\n\n\nipaddr_script.sh\n\n#!/bin/bash\n#This script informs users about IP address class\n\necho -e \"\\n\\n****** IP Address Classification ******\\n\"\n\nipaddr=null\n\nwhile ! [[ ${ipaddr} =~ .[0-9] ]] || [ ${#ipaddr} -gt 15 ] || [ ${#ipaddr} -lt 7 ] || [ ${firstoct} -lt 1 ] || [ ${firstoct} -gt 255 ] || [ ${secoct} -lt 1 ] || [ ${secoct} -gt 255 ] || [ ${thirdoct} -lt 1 ] || [ ${thirdoct} -gt 255 ] || [ ${fourthoct} -lt 1 ] || [ ${fourthoct} -gt 255 ]; do\n\n  echo -e \"\\nProvide IP Address: \"\n  \n  read ipaddr\n  \n  firstoct=`echo ${ipaddr} | awk -F'.' '{print $1}'`\n  secoct=`echo ${ipaddr} | awk -F'.' '{print $2}'`\n  thirdoct=`echo ${ipaddr} | awk -F'.' '{print $3}'`\n  fourthoct=`echo ${ipaddr} | awk -F'.' '{print $4}'`\n  \n  if [ ${#ipaddr} -gt 15 ]; then\n    echo -e \"\\nIP address is too long, try again...\"\n    \n  elif [ ${#ipaddr} -lt 7 ]; then\n    echo -e \"\\nIP address is too short, try again...\"\n    \n  elif ! [[ ${ipaddr} =~ .[0-9] ]]; then\n    echo -e \"\\nMust be a number, try again...\"\n    \n  elif [ ${firstoct} -lt 1 ] || [ ${firstoct} -gt 255 ] || [ ${secoct} -lt 1 ] || [ ${secoct} -gt 255 ] || [ ${thirdoct} -lt 1 ] || [ ${thirdoct} -gt 255 ] || [ ${fourthoct} -lt 1 ] || [ ${fourthoct} -gt 255 ]; then\n    echo -e \"\\nEach octect must be a number between 1-255, try again...\"\n    \n  fi\ndone\n\nsbmask=null\n\nwhile ! [[ ${sbmask} =~ [0-9] ]] || [ ${sbmask} -gt 32 ] || [ ${sbmask} -lt 1 ]; do\n  echo -e \"\\nHow many bits is the subnet mask?:\"\n\n  read sbmask\n  \n  if [ ${sbmask} -gt 32 ]; then\n    echo -e \"\\nThere are only 32 bits in a subnet mask, try again...\"\n    \n  elif [ ${sbmask} -lt 1 ]; then\n    echo -e \"\\nMust have at least 1 bit in the subnet mask, try again...\"\n\n  elif ! [[ ${sbmask} =~ [0-9] ]]; then\n    echo -e \"\\nMust be a number, try again...\"\n\n  fi\ndone\n\nif [ ${firstoct} -gt 0 ] && [ ${firstoct} -lt 128 ]; then\n  echo -e \"\\n** CLASS A ADDRESS **\"\n\nelif [ ${firstoct} -gt 127 ] && [ ${firstoct} -lt 192 ]; then\n  echo -e \"\\n** CLASS B ADDRESS **\"\n    \nelif [ ${firstoct} -gt 191 ] && [ ${firstoct} -lt 224 ]; then\n  echo -e \"\\n** CLASS C ADDRESS **\"\n\nelif [ ${firstoct} -gt 223 ] && [ ${firstoct} -lt 240 ]; then\n  echo -e \"\\n** CLASS D ADDRESS **\"\n    \nelif [ ${firstoct} -gt 239 ] && [ ${firstoct} -lt 256 ]; then\n  echo -e \"\\n** CLASS E ADDRESS **\"\n    \nelse\n  return\nfi\necho -e \"\\nIP Address: ${ipaddr}\"\n\nM=$(( 0xffffffff ^ ((1 &lt;&lt; (32-sbmask)) -1) ))\necho -e \"\\nSubnet Mask: $(( (M&gt;&gt;24) & 0xff )).$(( (M&gt;&gt;16) & 0xff )).$(( (M&gt;&gt;8) & 0xff )).$(( M & 0xff ))\"\n\necho -e \"\\nGoodbye!\\n\"\nreturn"
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#firewalld-selinux",
    "href": "posts/linux-admin/linux-admin.html#firewalld-selinux",
    "title": "Linux Administration Project",
    "section": "6.1 Firewalld & SELinux",
    "text": "6.1 Firewalld & SELinux\nMany turn firewalld off to make it easier to configure their services but it is far better to add the port rules that you need to each server for their respective services. In addition, it is a better practice to keep SELinux enabled and to change the security contexts where needed. Throughout the server configuration process these systems were constantly adjusted in the prototype network to allow the services to run but were never disabled. This ensures that the network is as hardened as it can be to intruders."
  },
  {
    "objectID": "posts/linux-admin/linux-admin.html#references",
    "href": "posts/linux-admin/linux-admin.html#references",
    "title": "Linux Administration Project",
    "section": "References",
    "text": "References\n\nNFS\nhttps://www.itzgeek.com/how-tos/linux/centos-how-tos/how-to-setup-nfs-server-on-centos-7-rhel-7-fedora-22.html\n\n\nNFS - Windows\nhttps://it.umn.edu/services-technologies/how-tos/network-file-system-nfs-mount-nfs-share\n\n\nLDAP\nhttps://www.itzgeek.com/how-tos/linux/centos-how-tos/step-step-openldap-server-configuration-centos-7-rhel-7.html\n\n\nLDAP Local User Migration\nhttps://www.itzgeek.com/how-tos/linux/centos-how-tos/migrate-local-users-ldap-accounts.html\n\n\nLDAP Automount Home Directories\nhttps://www.myfaqbase.com/q0001874-Software-OS-Unix-Linux-RHEL-7-RHCSA-How-to-configure-AutoFS-to-mount-user-home-directories-from-NFS-server.html\n\n\nLDAP TLS\nhttps://www.golinuxcloud.com/configure-openldap-with-tls-certificates/\n\n\nSamba\nhttps://linuxize.com/post/how-to-install-and-configure-samba-on-centos-7/\n\n\nPostfix Server\nhttps://www.server-world.info/en/note?os=CentOS_7&p=mail\n\n\nDovcote Server\nhttps://www.server-world.info/en/note?os=CentOS_7&p=mail&f=2"
  },
  {
    "objectID": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#purpose-of-document",
    "href": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#purpose-of-document",
    "title": "Deep Learning FastAI Model",
    "section": "1.1 Purpose of Document",
    "text": "1.1 Purpose of Document\nThe purpose of this document is to detail the building of deep learning models using a convolutional neural network architecture. The different techniques, models and methods used to improve performance will be discussed."
  },
  {
    "objectID": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#bee-vs-wasp",
    "href": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#bee-vs-wasp",
    "title": "Deep Learning FastAI Model",
    "section": "2.1 Bee vs Wasp",
    "text": "2.1 Bee vs Wasp\nFor this project I chose a Bee vs Wasp dataset found on Kaggle. I imported the dataset and created a new folder called ‚Äúimages‚Äù to which I added subfolders: ‚Äúbee1‚Äù, ‚Äúbee2‚Äù, ‚Äúwasp1‚Äù, ‚Äúwasp2‚Äù, ‚Äúother_insect‚Äù and ‚Äúother_noinsect‚Äù. The data loader in my custom train_models function then creates classes based on the folder structure and feeds that to the model. The data set itself isn‚Äôt the cleanest as it seems that some images have not been placed in the correct folder which will sometimes give the model wrong information. No doubt this will affect the accuracy that can be attained with this dataset.\n\n\n\n\n\n\nDataset\n\n\n\nView Bee vs Wasp dataset on Kaggle."
  },
  {
    "objectID": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#trial-and-error",
    "href": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#trial-and-error",
    "title": "Deep Learning FastAI Model",
    "section": "3.1 Trial and Error",
    "text": "3.1 Trial and Error\nI created a custom function named train_models that I could use to conduct my tests a little faster. With a trial and error approach, I began manually trying different learning rates, model types and image sizes, along with training models with unfrozen weights ( See Figure¬†1, Table¬†1, Figure¬†2 & Table¬†2 ). Eventually I thought I should start trying to automate some of these tuning methods and, by doing so, hopefully optimize the outcomes.\n\n\n\n\n\n\nNote\n\n\n\nView full details of the trial and error testing in the Experimenting section on the Google Colab Notebook.\n\n\n\n\n#Function to train models more easily\ndef train_models(image_size, batch_size, images_path, test_size, model_type):\n    #instructions for preparing data batches, size of images\n    #and normalize data\n    batch_tfms = [*aug_transforms(size=image_size),Normalize.from_stats(*imagenet_stats)]\n\n    #function for creating batches with specified parameters\n    data = ImageDataLoaders.from_folder(images_path,\n                                        valid_pct=test_size,\n                                        ds_tfms=batch_tfms,\n                                        item_tfms=Resize(460),\n                                        bs=batch_size)\n    \n    # test whether batch function is working with parameters\n    data.show_batch(max_n=9, figsize=(20,10))\n\n    #return the trained model\n    return vision_learner(data, model_type, metrics=error_rate).to_fp16()\n\nSource: Google Colab Notebook\n\n\n\n\n\nCode\n#image size\nimage_size = 224\n\n#batch size, number of images to transfer to GPU to train at one time\nbatch_size = 64\n\n#Image path\nimages_path = \"kaggle_bee_vs_wasp/images\"\n\n#test size\ntest_size = 0.2\n\n#CNN model\nmodel_type = resnet34\n\n#Create model with dataset and parameters\nlearn_resnet34 = train_models(image_size, batch_size, images_path, test_size, model_type)\n\n\n\n\n\nFigure¬†1. First resnet34 model test\n\n\n\n\nSource: Google Colab Notebook\n\n\n\n\n\nCode\n#train with discovered learning\n#rates and train two more epochs... may improve accuracy\nlearn_resnet34.fit_one_cycle(2, lr_max=slice(1e-6,1e-3))\n\n\n\n\n\n\n\n\nTable¬†1. First resnet34 best training results\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.179072\n0.169389\n0.055166\n02:12\n\n\n1\n0.105617\n0.161333\n0.046848\n02:08\n\n\n\n\n\n\nSource: Google Colab Notebook\n\n\n\n\n\nCode\n#image size\nimage_size = 224\n\n#batch size, number of images to transfer to GPU to train at one time\nbatch_size = 64\n\n#Image path\nimages_path = \"kaggle_bee_vs_wasp/images\"\n\n#test size\ntest_size = 0.2\n\n#CNN model\nmodel_type = resnet50\n\n#Try resnet50 with same image size as first resnet34 tests\nlearn_resnet50 = train_models(image_size, batch_size, images_path, test_size, model_type)\n\n\n\n\n\nFigure¬†2. First resnet50 model test\n\n\n\n\nSource: Google Colab Notebook\n\n\n\n\n\nCode\n#save where the model is currently at\nlearn_resnet50.save('stage_2')\n# freeze most of the weights again and train two more epochs\nlearn_resnet50.freeze()\nlearn_resnet50.fit_one_cycle(2)\n\n\n\n\n\n\n\n\nTable¬†2. First resnet50 best training results\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.152754\n0.199921\n0.056918\n04:58\n\n\n1\n0.082319\n0.159553\n0.042907\n04:59\n\n\n\n\n\n\nSource: Google Colab Notebook"
  },
  {
    "objectID": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#automating-hyperparameter-tuning",
    "href": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#automating-hyperparameter-tuning",
    "title": "Deep Learning FastAI Model",
    "section": "3.2 Automating Hyperparameter Tuning",
    "text": "3.2 Automating Hyperparameter Tuning\nIn research, I found a Python library called Optuna that could be used to automate hyperparameter tuning. Optuna does this by creating a ‚Äústudy‚Äù that runs a user specified amount of trials and uses an objective function to suggest user specified parameters to optimize for a certain metric. So in this case, I created a custom objective function named tune_hyperparameters that takes in learning rate, batch size, and weight decay parameters and returns the error rate of the model trained with those parameters. The Optuna optimize function then suggests hyperparameters that should start lowering the error rate of successive trials. I then wrote another custom function called optimization_study that ran the Optuna study using the tune_hyperparameters function. The optimization_study function also selects the trial that did the best and proceeds to unfreeze all of the weights and train the model again with the best found hyperparameters. Some of my initial tests with this automated hyperparameter tuning proved promising as I was able to get the error rate lower than I had previously gotten it.\n\n\n\n\n\n\nNote\n\n\n\nView full details of the automation testing in the Automate Hyperparameter Tuning section on the Google Colab Notebook.\n\n\n\n\n\n\n# Custom function to choose the best trial and unfreeze weights to train further\ndef optimization_study(selected_model):\n\n    # Create an Optuna study and optimize the objective function\n    study = optuna.create_study(direction=\"minimize\") # Minimize the error rate\n    study.optimize(lambda trial: tune_hyperparameters(trial, image_size, images_path, test_size, selected_model), n_trials=3)\n\n    # Print the best hyperparameters and the corresponding accuracy\n    best_params = study.best_params\n    best_error_rate = study.best_value\n    print(\"Best Hyperparameters:\", best_params)\n    print(\"Best Accuracy:\", best_error_rate)\n\n    #retrieve best model's state dict file\n    best_state_dict_file = f\"{selected_model}_state_dict_trial_{study.best_trial.number}.pth\"\n\n    # Get the best trial from the study\n    best_trial = study.trials[study.best_trial.number]\n\n    # Retrieve the hyperparameters of the best trial\n    hyperparameters = best_trial.params\n\n    # Access individual hyperparameters\n    learning_rate = hyperparameters[\"learning_rate\"]\n    batch_size = hyperparameters[\"batch_size\"]\n    weight_decay = hyperparameters[\"weight_decay\"]\n\n    #Create model with the same architecture as the best trial and load dict file into it\n    best_trial_learn = train_models(image_size, batch_size, images_path, test_size, selected_model)\n    best_trial_learn.model.load_state_dict(torch.load(best_state_dict_file))\n\n    #unfreeze all weights to train with optimal hyperparameters\n    best_trial_learn.unfreeze()\n    # Fit the model with the best trial's hyperparameters\n    best_trial_learn.fine_tune(4, base_lr=learning_rate, wd=weight_decay)\n\n    #close it back up\n    best_trial_learn.freeze()\n\n    #return the model with all of the best results\n    return best_trial_learn\n\nSource: Google Colab Notebook"
  },
  {
    "objectID": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#automate-testing-different-models",
    "href": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#automate-testing-different-models",
    "title": "Deep Learning FastAI Model",
    "section": "3.3 Automate Testing Different Models",
    "text": "3.3 Automate Testing Different Models\nAs I started to achieve some good results with my automations I decided to go even further. I wrote another custom function called try_models that loops through a list of different models, runs an Optuna study on it and saves the model state from the best trial from that particular study on that particular model. Once the try_models function has finished looping through the list of models it selects the model that achieved the lowest error rate, creates a learner from that model and loads the model state of the best trial from that model. It then proceeds to unfreeze all of the weights and train the model again with hyperparameters from that particular model‚Äôs best trail. After training is complete the function freezes the weights again, displays the results, and returns the model. I found some success using this new function as long as I kept the trial size relatively low as when I increased the trial size it exponentially increases compute time and quickly reaches the limits of free tier kernels.\n\n\n\n\n\n\nNote\n\n\n\nView full details of the try_models function automation testing in the Automate testing different models section on the Kaggle Notebook.\n\n\n\n\n# Custom function to try different models with the other automation functions\ndef try_models(image_size, images_path, test_size, models, trial_size):\n    best_trials = {}\n    for model in models:\n        best_trials[model.__name__] = optimization_study(image_size, images_path, test_size, model, trial_size)\n        \n    best_overall = min(best_trials,  key=lambda x: best_trials[x].value)\n    lowest_model = best_trials[best_overall]\n    print(\"\\n\\nBest Overall Model:\", lowest_model.user_attrs['model'].__name__)\n    print(\"Error Rate:\", lowest_model.value)\n    print(\"Load Model's state and retrain with best hyperparameters\")\n    \n    \n    #retrieve best model's state dict file\n    best_state_dict_file = f\"/kaggle/working/{lowest_model.user_attrs['model'].__name__}_state_dict_trial_{lowest_model.number}.pth\"\n\n    \n    # Retrieve the hyperparameters of the best trial\n    hyperparameters = lowest_model.params\n\n    # Access individual hyperparameters\n    learning_rate = hyperparameters[\"learning_rate\"]\n    batch_size = hyperparameters[\"batch_size\"]\n    weight_decay = hyperparameters[\"weight_decay\"]\n\n    #Create model with the same architecture as the best trial and load dict file into it\n    best_model_learn = train_models(image_size, batch_size, images_path, test_size, lowest_model.user_attrs[\"model\"])\n    best_model_learn.model.load_state_dict(torch.load(best_state_dict_file))\n\n    #unfreeze all weights to train with optimal hyperparameters\n    best_model_learn.unfreeze()\n    # Fit the model with the best trial's hyperparameters\n    best_model_learn.fine_tune(1, base_lr=learning_rate, wd=weight_decay)\n\n    #close it back up\n    best_model_learn.freeze()\n    \n    # Evaluate the model on the validation set\n    best_error_rate = best_model_learn.validate()[1]\n    \n    print(f\"\\n\\nFinal result after training model \"+lowest_model.user_attrs['model'].__name__+\" with:\")\n    print(\"Hyperparameters:\", hyperparameters)\n    print(\"Error Rate:\", best_error_rate)\n\n    \n    #return the model with all of the best results\n    return best_model_learn\n\nSource: Kaggle Notebook"
  },
  {
    "objectID": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#data-augmentation",
    "href": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#data-augmentation",
    "title": "Deep Learning FastAI Model",
    "section": "3.4 Data Augmentation",
    "text": "3.4 Data Augmentation\nI also briefly experimented with some data augmentation, namely randomly cropping to a 224x224 image size and introducing a random horizontal flip to the images. Tests with this didn‚Äôt seem to yield any improved results, in fact it seems it may have adversely affected model performance in training. I theorize that this didn‚Äôt have much effect because the dataset already possesses a great deal of randomness so injecting more isn‚Äôt advantageous."
  },
  {
    "objectID": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#usage-limits",
    "href": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#usage-limits",
    "title": "Deep Learning FastAI Model",
    "section": "4.1 Usage Limits",
    "text": "4.1 Usage Limits\nVery early on it was clear that usage limits of free tier kernels would significantly limit the ability to experiment, test and iterate. For this reason, the approach was taken to use more than one kernel so that when one reached its limit the other could be used to continue with the project. Google Colab and Kaggle were both used to complete this project and in the following two items ( 4.2 Google Colab & 4.3 Kaggle ) in this section I detail what each kernel was primarily used for. A notebook from each kernel is provided in this project submission, with Part 1 and Part 3 being included in the Google Colab notebook and Part 2 being included in the Kaggle notebook."
  },
  {
    "objectID": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#google-colab",
    "href": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#google-colab",
    "title": "Deep Learning FastAI Model",
    "section": "4.2 Google Colab",
    "text": "4.2 Google Colab\nI started my initial experimentation in Google Colab and that is why it starts with the heading Part 1. Part way through the refinement of my custom automation functions I reached my limit with Google Colab so Part 2 of my code is found in the Kaggle notebook. The final part of my testing and code can be found under Part 3 of the Google Colab notebook. In Part 3, I decided to purchase some Pay-As-You-Go compute so that I could continue the rest of my project without further delays."
  },
  {
    "objectID": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#kaggle",
    "href": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#kaggle",
    "title": "Deep Learning FastAI Model",
    "section": "4.3 Kaggle",
    "text": "4.3 Kaggle\nThe Kaggle notebook starts with the heading of Part 2 as it is the point where I switched from Google Colab. The Kaggle notebook only includes one part and it is where most of the refinements on my custom functions can be found. I was able to make some fairly large tests at the end of the Kaggle notebook but then reached my limit. At this point I switched back to finish things off in my Google Colab notebook under Part 3."
  },
  {
    "objectID": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#worst-performance",
    "href": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#worst-performance",
    "title": "Deep Learning FastAI Model",
    "section": "5.1 Worst Performance",
    "text": "5.1 Worst Performance\nI wasn‚Äôt able to test VGG16 to long before I ran into limit restrictions on the kernel but it wasn‚Äôt performing all that well from what was seen. Further investigation would be required to confirm that VGG16 is not a good model for this dataset. SqueezeNet models did not perform as well as the other models which is not surprising giving the size and architecture of SqueezeNet models ( See Figure¬†3 ). The 896x896 image size did not seem to yield better results and neither did batch sizes 16 and 64. Learning rate range 1e-5 - 1e-1 did not yield good results as well as weight decay range 1e-5 ‚Äì 1e-3.\n\n\n\nFigure¬†3. Best SqueezeNet model results after optimization automations were the worst results."
  },
  {
    "objectID": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#best-performance",
    "href": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#best-performance",
    "title": "Deep Learning FastAI Model",
    "section": "5.2 Best Performance",
    "text": "5.2 Best Performance\nAfter studying some of the tests I started to isolate that a batch size of 32 did consistently well. Along with training only with a 32 batch size I narrowed the learning rate range to 1e-3 ‚Äì 1e-2 and the weight decay range to 1e-5 -1e-4 as these ranges seems to provide the best results. In the end of all my testing the best performance I achieved was from a Resnet32 model trained with a 224 image size, 32 batch size, a learning rate of 3.102551277095900e-3 and a weight decay of 7.49113519525403e-05. This yielded a model with a training loss of 0.022758, valid loss of 0.065226, and error rate of 0.015762. These results show that the model is slightly overfitted but performing quite well. ( See Figure¬†4 )\n\n\n\nFigure¬†4. Best Resnet model results after optimization automations were the best performance."
  },
  {
    "objectID": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#model-training-video-walkthrough",
    "href": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#model-training-video-walkthrough",
    "title": "Deep Learning FastAI Model",
    "section": "Model Training Video Walkthrough",
    "text": "Model Training Video Walkthrough\nVideo"
  },
  {
    "objectID": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#references",
    "href": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#references",
    "title": "Deep Learning FastAI Model",
    "section": "References",
    "text": "References\nOptimization Library\nhttps://optuna.org/"
  },
  {
    "objectID": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#deployment",
    "href": "posts/intro-to-ai-fastai/intro-to-ai-fastai.html#deployment",
    "title": "Deep Learning FastAI Model",
    "section": "Deployment",
    "text": "Deployment\n\nDeployment Source Code\nView the source code for the model deployment on HuggingFace repository.\n\n\nGradio App\nView Gradio app for model deployment hosted on HuggingFace.\n\n\nDeployment Resources\nHugging Face - AI community & place to host ML deployments\nhttps://huggingface.co/\nGradio - Open-source Python library used to build machine learning/data science demos & web applications\nhttps://www.gradio.app/"
  },
  {
    "objectID": "posts/networking-cisco/networking-cisco.html",
    "href": "posts/networking-cisco/networking-cisco.html",
    "title": "Networking with Cisco Technologies",
    "section": "",
    "text": "Designed and constructed a fictional network with five (5) departments in two (2) locations using GNS3 simulation software. All departments were represented by Windows 10 VMs run on VMware and were configured to communicate with each other thru GNS3. Variable length subnetting from an address space of 172.16.16.0/20 was used to create department subnets. Routing protocol OSPF along with ACLs were used to allow departments to communicate with each other while at the same time preventing certain ones from reaching others. See figures below for full documentation of the project.\n\n\n\n\n\n\nExpand To Learn About Project Scenario\n\n\n\n\n\nThe head office is located in Vancouver and has three departments. These departments are Accounting, Administration, and Human Resources. The Accounting department uses 10 computers, Administration uses 19 computers, and Human Resources uses 3 computers.\nThe branch office is located in Kelowna and has two departments. These departments are Marketing and Sales. The Marketing department uses 16 computers, and the Sales department uses 45 computers.\n\n\n\n\n\n\n\n\nFigure¬†1. Network Diagram\n\n\n\n\n\n\n\n\nFigure¬†2. IP Address Scheme\n\n\n\n\n\n\n\n\nFigure¬†3. Access Control Lists\n\n\n\n\n\n\n\n\nFigure¬†4. Router Access Credentials\n\n\n\n\n\n\nListing¬†1. Vancouver Router Configuration\n!\n!\nversion 12.4\nservice timestamps debug datetime msec\nservice timestamps log datetime msec\nno service password-encryption\n!\nhostname Vancouver\n!\nboot-start-marker\nboot-end-marker\n!\nenable secret 5 $1$rCPC$Q34x6NTdMojTQHgQQwDe7/\n!\nno aaa new-model\nmemory-size iomem 5\nno ip icmp rate-limit unreachable\n!\n!\nip cef\nno ip domain lookup\n!\n!\n!\n!\n!\nip tcp synwait-time 5\n!\n!\ninterface Ethernet0/0\n  description Router Network\n  ip address 172.16.16.153 255.255.255.252\n  half-duplex\n!\ninterface Ethernet0/1\n  description HR Network\n  ip address 172.16.16.148 255.255.255.248\n  ip access-group 3 out\n  half-duplex\n!\ninterface Ethernet0/2\n  description Admin & SMTP/WebServer Network\n  ip address 172.16.16.84 255.255.255.224\n  ip access-group 110 out\n  half-duplex\n!\ninterface Ethernet0/3\n  description Accounting Network\n  ip address 172.16.16.139 255.255.255.240\n  ip access-group 2 out\n  half-duplex\n!\nrouter ospf 1\n  log-adjacency-changes\n  network 172.16.16.64 0.0.0.31 area 0\n  network 172.16.16.128 0.0.0.15 area 0\n  network 172.16.16.144 0.0.0.7 area 0\n  network 172.16.16.152 0.0.0.3 area 0\n!\nno ip http server\n!\nip forward-protocol nd\n!\n!\naccess-list 2 deny   172.16.16.96 0.0.0.31\naccess-list 2 deny   172.16.16.0 0.0.0.63\naccess-list 2 permit any\naccess-list 3 deny   172.16.16.0 0.0.0.63\naccess-list 3 permit any\naccess-list 110 deny   tcp 172.16.16.128 0.0.0.15 host 172.16.16.66 eq\nwww\naccess-list 110 deny   tcp 172.16.16.144 0.0.0.7 host 172.16.16.66 eq\nwww\naccess-list 110 deny   tcp 172.16.16.0 0.0.0.63 host 172.16.16.66 eq\nsmtp\naccess-list 110 deny   tcp 172.16.16.96 0.0.0.31 host 172.16.16.66 eq\nsmtp\naccess-list 110 permit ip any any\nno cdp log mismatch duplex\n!\ncontrol-plane\n!\nbanner motd\n\nWelcome to Vancouver\n\n!\nline con 0\n  exec-timeout 0 0\n  privilege level 15\n  logging synchronous\nline aux 0\n  exec-timeout 0 0\n  privilege level 15\n  logging synchronous\nline vty 0 4\n  password 1234\n  login\n!\n!\nend\n\n\nListing¬†2. Kelowna Router Configuration\n!\n!\nversion 12.4\nservice timestamps debug datetime msec\nservice timestamps log datetime msec\nno service password-encryption\n!\nhostname Kelowna\n!\nboot-start-marker\nboot-end-marker\n!\nenable secret 5 $1$dGub$MNu5a6gEp0IcO1T14Qlg4/\n!\nno aaa new-model\nmemory-size iomem 5\nno ip icmp rate-limit unreachable\n!\n!\nip cef\nno ip domain lookup\n!\n!\n!\n!\n!\nip tcp synwait-time 5\n!\n!\ninterface Ethernet0/0\n  description Router Network\n  ip address 172.16.16.154 255.255.255.252\n  half-duplex\n!\ninterface Ethernet0/1\n  description Sales Network\n  ip address 172.16.16.46 255.255.255.192\n  ip access-group 1 out\n  half-duplex\n!\ninterface Ethernet0/2\n  description Marketing Network\n  ip address 172.16.16.113 255.255.255.224\n  ip access-group 4 out\n  half-duplex\n!\ninterface Ethernet0/3\n  description Nothing\n  no ip address\n  shutdown\n  half-duplex\n!\nrouter ospf 1\n  log-adjacency-changes\n  network 172.16.16.0 0.0.0.63 area 0\n  network 172.16.16.96 0.0.0.31 area 0\n  network 172.16.16.152 0.0.0.3 area 0\n!\nno ip http server\n!\nip forward-protocol nd\n!\n!\naccess-list 1 deny   172.16.16.128 0.0.0.15\naccess-list 1 deny   172.16.16.96 0.0.0.31\naccess-list 1 permit any\naccess-list 4 deny   172.16.16.0 0.0.0.63\naccess-list 4 permit any\nno cdp log mismatch duplex\n!\ncontrol-plane\n!\nbanner motd\n\n\nWelcome to Kelowna\n\n\n!\nline con 0\n  exec-timeout 0 0\n  privilege level 15\n  logging synchronous\nline aux 0\n  exec-timeout 0 0\n  privilege level 15\n  logging synchronous\nline vty 0 4\n  password 1234\n  login\n!\n!\nend"
  },
  {
    "objectID": "posts/networking-cisco/networking-cisco.html#network-diagram",
    "href": "posts/networking-cisco/networking-cisco.html#network-diagram",
    "title": "Networking with Cisco Technologies",
    "section": "",
    "text": "Figure¬†1. Network Diagram"
  },
  {
    "objectID": "posts/networking-cisco/networking-cisco.html#ip-address-scheme",
    "href": "posts/networking-cisco/networking-cisco.html#ip-address-scheme",
    "title": "Networking with Cisco Technologies",
    "section": "",
    "text": "Figure¬†2. IP Address Scheme"
  },
  {
    "objectID": "posts/networking-cisco/networking-cisco.html#access-control-lists",
    "href": "posts/networking-cisco/networking-cisco.html#access-control-lists",
    "title": "Networking with Cisco Technologies",
    "section": "",
    "text": "Figure¬†3. Access Control Lists"
  },
  {
    "objectID": "posts/networking-cisco/networking-cisco.html#router-access-credentials",
    "href": "posts/networking-cisco/networking-cisco.html#router-access-credentials",
    "title": "Networking with Cisco Technologies",
    "section": "",
    "text": "Figure¬†4. Router Access Credentials"
  },
  {
    "objectID": "posts/networking-cisco/networking-cisco.html#router-configurations",
    "href": "posts/networking-cisco/networking-cisco.html#router-configurations",
    "title": "Networking with Cisco Technologies",
    "section": "",
    "text": "Listing¬†1. Vancouver Router Configuration\n!\n!\nversion 12.4\nservice timestamps debug datetime msec\nservice timestamps log datetime msec\nno service password-encryption\n!\nhostname Vancouver\n!\nboot-start-marker\nboot-end-marker\n!\nenable secret 5 $1$rCPC$Q34x6NTdMojTQHgQQwDe7/\n!\nno aaa new-model\nmemory-size iomem 5\nno ip icmp rate-limit unreachable\n!\n!\nip cef\nno ip domain lookup\n!\n!\n!\n!\n!\nip tcp synwait-time 5\n!\n!\ninterface Ethernet0/0\n  description Router Network\n  ip address 172.16.16.153 255.255.255.252\n  half-duplex\n!\ninterface Ethernet0/1\n  description HR Network\n  ip address 172.16.16.148 255.255.255.248\n  ip access-group 3 out\n  half-duplex\n!\ninterface Ethernet0/2\n  description Admin & SMTP/WebServer Network\n  ip address 172.16.16.84 255.255.255.224\n  ip access-group 110 out\n  half-duplex\n!\ninterface Ethernet0/3\n  description Accounting Network\n  ip address 172.16.16.139 255.255.255.240\n  ip access-group 2 out\n  half-duplex\n!\nrouter ospf 1\n  log-adjacency-changes\n  network 172.16.16.64 0.0.0.31 area 0\n  network 172.16.16.128 0.0.0.15 area 0\n  network 172.16.16.144 0.0.0.7 area 0\n  network 172.16.16.152 0.0.0.3 area 0\n!\nno ip http server\n!\nip forward-protocol nd\n!\n!\naccess-list 2 deny   172.16.16.96 0.0.0.31\naccess-list 2 deny   172.16.16.0 0.0.0.63\naccess-list 2 permit any\naccess-list 3 deny   172.16.16.0 0.0.0.63\naccess-list 3 permit any\naccess-list 110 deny   tcp 172.16.16.128 0.0.0.15 host 172.16.16.66 eq\nwww\naccess-list 110 deny   tcp 172.16.16.144 0.0.0.7 host 172.16.16.66 eq\nwww\naccess-list 110 deny   tcp 172.16.16.0 0.0.0.63 host 172.16.16.66 eq\nsmtp\naccess-list 110 deny   tcp 172.16.16.96 0.0.0.31 host 172.16.16.66 eq\nsmtp\naccess-list 110 permit ip any any\nno cdp log mismatch duplex\n!\ncontrol-plane\n!\nbanner motd\n\nWelcome to Vancouver\n\n!\nline con 0\n  exec-timeout 0 0\n  privilege level 15\n  logging synchronous\nline aux 0\n  exec-timeout 0 0\n  privilege level 15\n  logging synchronous\nline vty 0 4\n  password 1234\n  login\n!\n!\nend\n\n\nListing¬†2. Kelowna Router Configuration\n!\n!\nversion 12.4\nservice timestamps debug datetime msec\nservice timestamps log datetime msec\nno service password-encryption\n!\nhostname Kelowna\n!\nboot-start-marker\nboot-end-marker\n!\nenable secret 5 $1$dGub$MNu5a6gEp0IcO1T14Qlg4/\n!\nno aaa new-model\nmemory-size iomem 5\nno ip icmp rate-limit unreachable\n!\n!\nip cef\nno ip domain lookup\n!\n!\n!\n!\n!\nip tcp synwait-time 5\n!\n!\ninterface Ethernet0/0\n  description Router Network\n  ip address 172.16.16.154 255.255.255.252\n  half-duplex\n!\ninterface Ethernet0/1\n  description Sales Network\n  ip address 172.16.16.46 255.255.255.192\n  ip access-group 1 out\n  half-duplex\n!\ninterface Ethernet0/2\n  description Marketing Network\n  ip address 172.16.16.113 255.255.255.224\n  ip access-group 4 out\n  half-duplex\n!\ninterface Ethernet0/3\n  description Nothing\n  no ip address\n  shutdown\n  half-duplex\n!\nrouter ospf 1\n  log-adjacency-changes\n  network 172.16.16.0 0.0.0.63 area 0\n  network 172.16.16.96 0.0.0.31 area 0\n  network 172.16.16.152 0.0.0.3 area 0\n!\nno ip http server\n!\nip forward-protocol nd\n!\n!\naccess-list 1 deny   172.16.16.128 0.0.0.15\naccess-list 1 deny   172.16.16.96 0.0.0.31\naccess-list 1 permit any\naccess-list 4 deny   172.16.16.0 0.0.0.63\naccess-list 4 permit any\nno cdp log mismatch duplex\n!\ncontrol-plane\n!\nbanner motd\n\n\nWelcome to Kelowna\n\n\n!\nline con 0\n  exec-timeout 0 0\n  privilege level 15\n  logging synchronous\nline aux 0\n  exec-timeout 0 0\n  privilege level 15\n  logging synchronous\nline vty 0 4\n  password 1234\n  login\n!\n!\nend"
  },
  {
    "objectID": "posts/emcs/emcs.html",
    "href": "posts/emcs/emcs.html",
    "title": "Microsoft Exchange Server Network",
    "section": "",
    "text": "Deployed an Exchange server environment using Microsoft Exchange Server 2016. Created three (3) domain controllers, two (2) mailbox servers, and one (1) edge transport server on VMware. One (1) of the domain controllers was running Server Core. Formatted disks with different file systems and created simple, spanned, stripped, mirrored, and RAID-5 volumes. Installed and configured Active Directory including creating and managing OU structure, users, and groups. Created an Active Directory backup and restored from backup. Installed and upgraded Exchange Server 2016. Created mailbox databases in a DAG. Configured namespaces, SSL certificates, and mail flow. Spent extensive time using PowerShell and Exchange Management Shell for installs and configuration. See project screenshots below.\n\n\n\n\n\nFigure¬†1. Domain Controller 1 - IP Configurations\n\n\n\n\n\nFigure¬†2. Domain Controller 3 (Server Core) - IP Configurations\n\n\n\n\n\nFigure¬†3. Domain Controller 3 (Server Core) - Firewall Configurations\n\n\n\n\n\n\n\n\nFigure¬†4. Domain Controller 2 - Raid Volumes\n\n\n\n\n\n\n\n\nFigure¬†5. Active Directory Installation\n\n\n\n\n\nFigure¬†6. Active Directory - OUs & Users\n\n\n\n\n\n\n\n\nFigure¬†7. Exchange Server Install\n\n\n\n\n\nFigure¬†8. Mailbox Databases\n\n\n\n\n\nFigure¬†9. Recipients\n\n\n\n\n\nFigure¬†10. Resource Mailboxes & Distribution Groups"
  },
  {
    "objectID": "posts/emcs/emcs.html#domain-controller-configurations",
    "href": "posts/emcs/emcs.html#domain-controller-configurations",
    "title": "Microsoft Exchange Server Network",
    "section": "",
    "text": "Figure¬†1. Domain Controller 1 - IP Configurations\n\n\n\n\n\nFigure¬†2. Domain Controller 3 (Server Core) - IP Configurations\n\n\n\n\n\nFigure¬†3. Domain Controller 3 (Server Core) - Firewall Configurations"
  },
  {
    "objectID": "posts/emcs/emcs.html#file-systems",
    "href": "posts/emcs/emcs.html#file-systems",
    "title": "Microsoft Exchange Server Network",
    "section": "",
    "text": "Figure¬†4. Domain Controller 2 - Raid Volumes"
  },
  {
    "objectID": "posts/emcs/emcs.html#active-directory",
    "href": "posts/emcs/emcs.html#active-directory",
    "title": "Microsoft Exchange Server Network",
    "section": "",
    "text": "Figure¬†5. Active Directory Installation\n\n\n\n\n\nFigure¬†6. Active Directory - OUs & Users"
  },
  {
    "objectID": "posts/emcs/emcs.html#exhange-server",
    "href": "posts/emcs/emcs.html#exhange-server",
    "title": "Microsoft Exchange Server Network",
    "section": "",
    "text": "Figure¬†7. Exchange Server Install\n\n\n\n\n\nFigure¬†8. Mailbox Databases\n\n\n\n\n\nFigure¬†9. Recipients\n\n\n\n\n\nFigure¬†10. Resource Mailboxes & Distribution Groups"
  },
  {
    "objectID": "posts/laserman/laserman.html",
    "href": "posts/laserman/laserman.html",
    "title": "Retro C++ Game LaserMan",
    "section": "",
    "text": "Play Game\n\n\n\n\n\n\nPlayer Keyboard Controls\n\n\n\n\n\n\n\n\nMove\nArrow Keys\nSelect\nEnter\n\n\nEscape Program\nEsc\n\n\n\n\n\n\nüöÄ Play Game\nDownload, unzip and open LaserMan.exe (Only runs on Windows)\n\n\n\n\n\nRetro Game\nProject to create a retro game using a beginner‚Äôs game-development framework called Playbuffer all written in C++ strictly for Windows. Programming algorithms and techniques such as state machines and object oriented programming were developed in the game loop.\n\n\n\n\n\n\nSource Code\n\n\n\nView source code on Github repository.\n\n\n\n\nVideo Walkthrough\nVideo"
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#purpose-of-document",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#purpose-of-document",
    "title": "Hotel Booking System Mock Design",
    "section": "1.1 Purpose of Document",
    "text": "1.1 Purpose of Document\nThe purpose of this document is to provide system designs to use in the development of the hotel booking system for City and Resort hotels."
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#scope",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#scope",
    "title": "Hotel Booking System Mock Design",
    "section": "1.2 Scope",
    "text": "1.2 Scope\nThe scope of the project involves an examination of the business scenario to ascertain how best to design, develop, and improve upon the proposed hotel booking system. In addition, creation of system designs and implementation documentation must be produced to drive the development of the project. The proposed solutions must include detailed logical & physical Entity-Relationship Diagrams, a Context Diagram, and up to Level 2 Data Flow Diagrams."
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#waterfall",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#waterfall",
    "title": "Hotel Booking System Mock Design",
    "section": "2.1 Waterfall",
    "text": "2.1 Waterfall\nThe Waterfall methodology contains five phases that are as follows: Requirements, Design, Implementation, Verification and Maintenance. Each of these phases are present in most methodologies however with the Waterfall approach each phase is followed by the next in strict fashion. The team can only progress to the next phase when the current phase has been completed and you cannot revert back to a previous phase. This approach is useful when a high level of reliability is needed for a project."
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#agile",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#agile",
    "title": "Hotel Booking System Mock Design",
    "section": "2.2 Agile",
    "text": "2.2 Agile\nThe Agile method is an iterative approach that allows for similar phases as Waterfall to be engaged simultaneously and in no specific order. The team is able to work in small increments allowing for customer input regularly. This methodology is far more flexible in terms of adapting to changes in customer wants and needs as they see the project develop."
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#preferred-software-development-methodology",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#preferred-software-development-methodology",
    "title": "Hotel Booking System Mock Design",
    "section": "2.3 Preferred Software Development Methodology",
    "text": "2.3 Preferred Software Development Methodology\nThe fact that there are two hotels that will be using this system in essence means that there two clients to consider in the development of this project. Each client has unique requirements that differ from one another and are subject to change. As the hospitality industry is fast paced and endeavours to adapt to ever changing customer opinions, the Agile methodology is best suited for this project. As stated above, Waterfall is great for certain projects but is highly inflexible while Agile allows for development teams to incorporate client input in small, digestible increments. This approach will translate to a product that provides more utility to the customer which in turn will result in higher customer satisfaction. ( See Appendix ‚Äì Waterfall Methodology & Agile Methodology )"
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#logical-entity-relationship-diagram",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#logical-entity-relationship-diagram",
    "title": "Hotel Booking System Mock Design",
    "section": "3.1 Logical Entity-Relationship Diagram",
    "text": "3.1 Logical Entity-Relationship Diagram\nThe four entities in this diagram are as follows: Customer, City Reservation, Resort Reservation and Invoice. Each entity has a primary key that consists of a uniquely generated number. The system is purposefully designed with no weak entities and foreign keys as this is not advisable to create a robust system. The Customer can either book a reservation at the City or Resort hotel. There is a need to delineate the City and Resort hotel reservations because of their individual discount policies. Each hotel will only reward their customers with a discount when they have previously stayed at their specific location before. In addition, the Resort hotel will only provide a discount to customers who haven‚Äôt had any cancellations at their location in the past year. Therefore the Resort Reservation entity has an addition attribute labelled ‚ÄúCancelled‚Äù that records whether any of the reservations have been cancelled. With the information supplied from the reservation entities the Invoice is populated. ( See Figure¬†1 )\n\n\n\nFigure¬†1. Logical Entity-Relationship Diagram"
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#physical-entity-relationship-diagram",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#physical-entity-relationship-diagram",
    "title": "Hotel Booking System Mock Design",
    "section": "3.2 Physical Entity-Relationship Diagram",
    "text": "3.2 Physical Entity-Relationship Diagram\nThe invoice entity contains a composite and multivalued attribute labelled ‚ÄúPayment‚Äù that allows for storage of the date and amount for payments made towards the total. When payments are made the ‚ÄúAmount Owing‚Äù attribute on the entry is updated accordingly. ( See Figure¬†2 )\n\n\n\nFigure¬†2. Physical Entity-Relationship Diagram"
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#data-fields-with-sample-data",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#data-fields-with-sample-data",
    "title": "Hotel Booking System Mock Design",
    "section": "3.3 Data Fields with Sample Data",
    "text": "3.3 Data Fields with Sample Data\n\n\n\nFigure¬†3. Data Fields with Sample Data"
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#context-diagram",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#context-diagram",
    "title": "Hotel Booking System Mock Design",
    "section": "4.1 Context Diagram",
    "text": "4.1 Context Diagram\nSix (6) entities: Customer, City Hotel, Resort Hotel, Car Parking Agency, Restaurant and ABC Bank interact with the system from a data flow perspective. A hotel only interacts with the system if the customer has chosen the specified hotel. Each entity‚Äôs interactions with the system will be described in further depth in the items to follow. ( See Figure¬†4 )\n\n\n\nFigure¬†4. Context Diagram"
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#level-1-dfd",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#level-1-dfd",
    "title": "Hotel Booking System Mock Design",
    "section": "4.2 Level 1 DFD",
    "text": "4.2 Level 1 DFD\nThere are three (3) processes depicted at level 1 that handle the flow of data for the system. Process 1, ‚ÄúBooking‚Äù, involves making a reservation, obtaining missing information for the reservation and cancelling the reservation. Process 2, ‚ÄúCheck-In‚Äù, is where the customer checks into their room and makes an initial payment. Process 3, ‚ÄúCheck-Out‚Äù, ends the customer‚Äôs interaction with the system by settling the remaining balance on the invoice and paying the parking invoice if the customer has opted for parking. ( See Figure¬†5 )\n\n\n\nFigure¬†5. Level 1 Data Flow Diagram"
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#level-2-dfd-booking-process-1",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#level-2-dfd-booking-process-1",
    "title": "Hotel Booking System Mock Design",
    "section": "4.3 Level 2 DFD ‚Äì Booking Process 1",
    "text": "4.3 Level 2 DFD ‚Äì Booking Process 1\nThere are five (5) sub-processes depicted at level 2 of ‚ÄúBooking‚Äù Process 1. In Process 1.1 the customer submits their customer details which are then stored. Process 1.2 generates room and date availability information by examining current reservations which is then used by the customer to submit their reservation preferences. In Process 1.3 the reservation details are stored and the hotel sends the customer a reservation code and request, in the form of an email, to submit missing information. The only none mandatory fields that may be missing are ‚ÄúFood Requirements‚Äù and ‚ÄúParking‚Äù. ( See Figure¬†1, Figure¬†2 and Figure¬†3 ) Process 1.4 gives the customer an opportunity to submit the missing information by clicking a link provided in the information request email and filling in the missing fields. This new information is then sent to the hotel, restaurant and parking agency along with being saved in the customer‚Äôs reservation entry. Process 1.5 allows the customer to cancel the reservation if desired. When a cancellation is made the ‚ÄúCancellation‚Äù field is updated if it is a Resort reservation entry or it deletes the entry in the case of a City reservation. All relevant parties are then informed of the cancellation. ( See Figure¬†6 )\n\n\n\nFigure¬†6. Level 2 Data Flow Diagram Booking Process 1"
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#level-2-dfd-check-in-process-2",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#level-2-dfd-check-in-process-2",
    "title": "Hotel Booking System Mock Design",
    "section": "4.4 Level 2 DFD ‚Äì Check-In Process 2",
    "text": "4.4 Level 2 DFD ‚Äì Check-In Process 2\nThere are four (4) sub-processes depicted at level 2 of ‚ÄúCheck-In‚Äù Process 2. In Process 2.1 the customer submits their reservation code which is then used to extract the customer‚Äôs details and reservation. This information is used by the hotel to generate an invoice which is then stored and a copy is sent to the customer in Process 2.2. In Process 2.3 the customer submits payment information which is then received by ABC bank along with the invoice. In Process 2.4 the bank handles the payment, sends payment confirmation to all relevant parties and the invoice entry is updated with payment details. ( See Figure¬†7 )\n\n\n\nFigure¬†7. Level 2 Data Flow Diagram Check-In Process 2"
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#level-2-dfd-check-out-process-3",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#level-2-dfd-check-out-process-3",
    "title": "Hotel Booking System Mock Design",
    "section": "4.5 Level 2 DFD ‚Äì Check-Out Process 3",
    "text": "4.5 Level 2 DFD ‚Äì Check-Out Process 3\nThere are three (3) sub-processes depicted at level 2 of ‚ÄúCheck-Out‚Äù Process 3. In Process 3.1 the customer submits their reservation code which is then used by the hotel to bring up the customer‚Äôs details, reservation and invoice. The customer details and reservation are also sent to the Car Parking Agency which uses Process 3.2 to send the customer a parking invoice along with their hotel invoice. In Process 3.3 the customer submits payment information for both invoices, which is then received by ABC bank along with both invoices. In Process 3.4 the bank processes the payment and sends payment confirmation to all relevant parties and the hotel invoice entry is updated with payment details. ( See Figure¬†8 )\n\n\n\nFigure¬†8. Level 2 Data Flow Diagram Check-Out Process 3"
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#additional-review-process",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#additional-review-process",
    "title": "Hotel Booking System Mock Design",
    "section": "5.1 Additional Review Process",
    "text": "5.1 Additional Review Process\nAn improvement upon the system could be achieved by adding a fourth process at level 1 to prompt the customer to provide a review. The review information could then be stored in an additional field in the reservation data stores. This review information could then be analyzed by AI technology to produce actionable suggestions on how to improve the customer‚Äôs experience."
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#sentiment-intent-analysis",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#sentiment-intent-analysis",
    "title": "Hotel Booking System Mock Design",
    "section": "5.2 Sentiment & Intent Analysis",
    "text": "5.2 Sentiment & Intent Analysis\nNatural language processing could be employed to analyze thousands of reviews to identify recurring themes and topics reported on by customers. These can then be rated so that hotel staff can see how customers feel and why they feel that way. This would allow for staff to see where best to make improvements to their services thereby increasing customer satisfaction. ( See Appendix ‚Äì Sentiment & Intent Analysis )"
  },
  {
    "objectID": "posts/dev-design-assignment1/design-dev-assignment1.html#references",
    "href": "posts/dev-design-assignment1/design-dev-assignment1.html#references",
    "title": "Hotel Booking System Mock Design",
    "section": "References",
    "text": "References\n\nWaterfall Methodology\nhttps://www.projectmanager.com/guides/waterfall-methodology/\n\n\nAgile Methodology\nhttps://www.atlassian.com/agile\n\n\n\n\nSentiment & Intent Analysis\nhttps://www.lexalytics.com/technology/sentiment-analysis/\nhttps://www.lexalytics.com/technology/intentions/"
  },
  {
    "objectID": "posts/unreal-design-patterns/unreal-design-patterns.html#command-design-pattern-c",
    "href": "posts/unreal-design-patterns/unreal-design-patterns.html#command-design-pattern-c",
    "title": "Programming Design Patterns",
    "section": "2.1 Command Design Pattern (C++)",
    "text": "2.1 Command Design Pattern (C++)\nCreated C++ classes that inherit from UObject class. Three command child classes(Jump, Run and Fire) inherit from a base command class. Command objects are created by the level blueprint based on keyboard and mouse inputs. These command objects then go on to execute the specific command they were designed for."
  },
  {
    "objectID": "posts/unreal-design-patterns/unreal-design-patterns.html#state-machine-design-pattern-c",
    "href": "posts/unreal-design-patterns/unreal-design-patterns.html#state-machine-design-pattern-c",
    "title": "Programming Design Patterns",
    "section": "2.2 State Machine Design Pattern (C++)",
    "text": "2.2 State Machine Design Pattern (C++)\nCreated C++ state classes are that inherit from UObject class and are managed by a StateManager class that inherits from Actor component class. The StateManager actor component object is created and attached to the enemy character class. The StateManager component then creates the three different state objects, switches the current state based on certain conditions and runs the current state."
  },
  {
    "objectID": "posts/unreal-design-patterns/unreal-design-patterns.html#object-pool-design-pattern-blueprints",
    "href": "posts/unreal-design-patterns/unreal-design-patterns.html#object-pool-design-pattern-blueprints",
    "title": "Programming Design Patterns",
    "section": "2.3 Object Pool Design Pattern (Blueprints)",
    "text": "2.3 Object Pool Design Pattern (Blueprints)\nCreated Blueprint BulletPool class actor component that attaches to actors and created a set number of bullets from the blueprint bullet class. The bulletpool than attaches the created bullets to the character and when the chsaracter‚Äôs fire method is invoked it uses the bullets from the bullet pool. If the bullet pool becomes empty then the player must wait for it to refill before firing more bullets."
  },
  {
    "objectID": "posts/unreal-design-patterns/unreal-design-patterns.html#prototype-design-pattern-blueprints",
    "href": "posts/unreal-design-patterns/unreal-design-patterns.html#prototype-design-pattern-blueprints",
    "title": "Programming Design Patterns",
    "section": "2.4 Prototype Design Pattern (Blueprints)",
    "text": "2.4 Prototype Design Pattern (Blueprints)\nCreated Blueprint spawn classes that spawn different enemy characters from blueprint child enemy character classes.\nOne type of spawn class has a public variable that can be set in the unreal inspector for each instance that stores a specific enemy character class. It then spawns a character based on the saved enemy character class and saves it and continues to invoke that intial spawned character‚Äôs Clone method to spawn more characters of that class. This spawner creates and stores only one prototype of one type of enemy to spawn further enemies from.\nThe other type of spawn class stores all of the different enemy classes. It randomly selects an enemy class from the list of enemy classes, spawns an instance of this class, runs the Clone method of that instance to spawn an enemy, and finally destroys the initial instance of the enemy. So this spawner type can spawn any type of enemy by creating and using a prototype of that enemy."
  },
  {
    "objectID": "posts/wireless-networking/wireless-networking.html#purpose-of-document",
    "href": "posts/wireless-networking/wireless-networking.html#purpose-of-document",
    "title": "Wireless Technology Networking",
    "section": "1.1 Purpose of Document",
    "text": "1.1 Purpose of Document\nThe purpose of this document is to provide a secure, reliable, and cost effective solution for the Acme Corp Infrastructure Project. It details the physical and logical requirements and how to address those in the best manner possible."
  },
  {
    "objectID": "posts/wireless-networking/wireless-networking.html#scope",
    "href": "posts/wireless-networking/wireless-networking.html#scope",
    "title": "Wireless Technology Networking",
    "section": "1.2 Scope",
    "text": "1.2 Scope\nScope can be split into two parts; one being the establishment of a wireless point-to-point link between Landmark 3 and Landmark 2 buildings and the other creating a WLAN network at the CAT facility in Landmark 3 on the ground floor. However, the proposed solution was designed in such a way to address potential contingencies as they arise."
  },
  {
    "objectID": "posts/wireless-networking/wireless-networking.html#equipment-pricing",
    "href": "posts/wireless-networking/wireless-networking.html#equipment-pricing",
    "title": "Wireless Technology Networking",
    "section": "2.1 Equipment / Pricing",
    "text": "2.1 Equipment / Pricing\n\n\n\n2.1.1\nTwo (2) MikroTik mANTBox 52 15s Units ( Antenna mounts included )\n$456.85\n\n\n2.1.2\nTwo (2) WC-44 Outdoor Enclosures\n$211.38\n\n\n2.1.3\nTwo (2) Pole Mounting Assemblies\n$100.93\n\n\n2.1.4\nTwo (2) Heavy Duty, High-speed Cat8 Ethernet Cables ( 150ft outdoor cables )\n$165.98\n\n\n2.1.5\nOne (1) UniFi EdgeSwitch 16XP\n$425.00\n\n\n2.1.6\nOne (1) Netgate 3100 MAX pfSense+ Firewall\n$442.00\n\n\n2.1.7\nNine (9) UniFi WiFi 6 Long-Range Access Points ( See Cabling )\n$1,611.00\n\n\n\nTOTAL\n$3,413.14\n\n\n\n\n\n\n\n\n\nPrices are estimated based on current market costs as of Dec 2021 and are subject to change. Only includes hardware costs.\n\n\n\n\n\n\n\n\n\n\n\n\nCabling\n\n\n\nAdditional subcontractor Cat5 cabling charges may added.\n\n\n\n\n\n\n\n\nNote\n\n\n\nURLs and Data Sheets for equipment are referenced in Appendix."
  },
  {
    "objectID": "posts/wireless-networking/wireless-networking.html#installation",
    "href": "posts/wireless-networking/wireless-networking.html#installation",
    "title": "Wireless Technology Networking",
    "section": "2.2 Installation",
    "text": "2.2 Installation\n\n2.2.1 Point-to-point Connection ‚Äì Antenna Mounting Locations\nThere are two buildings that sit between the target locations. The Ecco supply building is one of them but poses no threat of interference with the point-to-point link as it is only 2 storeys tall, which sits well below the height of the antenna installations. The Landmark 6 building is taller than both Landmark 2 & 3 buildings but doesn‚Äôt block the line of sight between them. However, Landmark 6 might encroach on the fresnel zone of the link if not properly placed. Therefore the antenna on Landmark 3 should be installed on the roof at the SE corner and the antenna on Landmark 2 should be installed on the roof at the NE corner. ( See Figure¬†1 )\n\n\n\n\n\n\n\n(a) Surrounding Building Heights\n\n\n\n\n\n\n\n(b) Antenna Mounts\n\n\n\n\nFigure¬†1. Antenna Mounting Locations\n\n\n\n\n2.2.2 Point-to-point Connection ‚Äì Landmark 2\nTo connect services from the electrical room on the 3rd floor to the roof will require a minimum of 37m of Cat8 ethernet cable. A 150ft cable is suggested for this solution to give some extra leway. The pole mount will need to be installed on the NE corner of the roof. The enclosure that is included with the antenna/base station does not have a sufficient rating for the weather conditions experienced year round in Kelowna. Therefore, they should be held in a WC-44 enclosure that is included in this solution. Included with the antenna/base station is one (1) Gigabit PoE injector cable with shielded connector. If there is no PoE device in the electrical room to connect to the base station then the PoE injector cable can be used in conjuction with a 50ft extension cord to reach a power supply located on the roof. Attach grounding wire to the grounding screw, then attach the other end of the grounding wire to the grounded mast. The antenna must be installed at an downtilt angle of 7.7244¬∞ degrees based on calculations below. ( See Figure¬†2 )\nDowntilt Ang = tan-1 [(Landmark 2 Hgt + Ant. Hgt) - (Landmark 3 Hgt + Ant. Hgt)]/Distance\n7.7244¬∞ deg = tan-1 [(50m + 2m) - (30m + 2m) / 145.45m]\n\n\n2.2.3 Point-to-point Connection ‚Äì Landmark 3\nTo connect services from the meet-me room on the basement floor to the roof will require a minimum of 35m of Cat8 ethernet cable. A 150ft cable is suggested for this solution to give some extra leway. The pole mount will need to be installed on the SE corner of the roof. It is suggested that one (1) PoE UniFi EdgeSwitch 16XP be installed in the wiring closet of the basement and this will serve as both a power source and data connection for the base station. During installation the base station should be connected to ethernet port 1 on the switch. Attach grounding wire to the grounding screw, then attach the other end of the grounding wire to the grounded mast. The antenna must be installed at an uptilt angle of -7.7244¬∞ degrees based on calculations below. ( See Figure¬†2 )\nUptilt Ang = tan-1 [(Landmark 3 Hgt + Ant. Hgt) - (Landmark 2 Hgt + Ant. Hgt)]/Distance\n-7.7244¬∞ deg = tan-1 [(30m + 2m) - (50m + 2m) / 145.45m]\n\n\n\nFigure¬†2. Antenna Angles\n\n\n\n\n2.2.4 WLAN Network\nWiFi coverage is needed on the ground floor of CAT facilities in the Landmark 3 building. Nine (9) UniFi WiFi 6 Long-Range Access Points mounted on the ceiling at the locations depicted in Figure¬†3 will provide superior coverage of the space. Each access point should be connected to the PoE switch located in the wiring closet with Cat5 cables. The access points should be connected to the switch starting from ethernet port 2 to ethernet port 10. The Netgate firewall device should be located in the wiring closet with the switch and connected to port 16 on the switch, leaving five (5) ports available for future additions if need be. For further discussion of access point configurations and coverage reference Section 3, items 3.2.2 and 3.2.3 of this document.\n\n\n\nFigure¬†3. Access Point Locations"
  },
  {
    "objectID": "posts/wireless-networking/wireless-networking.html#network-topology",
    "href": "posts/wireless-networking/wireless-networking.html#network-topology",
    "title": "Wireless Technology Networking",
    "section": "3.1 Network Topology",
    "text": "3.1 Network Topology\n\n\n\nFigure¬†4. Proposed Network Design"
  },
  {
    "objectID": "posts/wireless-networking/wireless-networking.html#proposed-network-configuration",
    "href": "posts/wireless-networking/wireless-networking.html#proposed-network-configuration",
    "title": "Wireless Technology Networking",
    "section": "3.2 Proposed Network Configuration",
    "text": "3.2 Proposed Network Configuration\nProposed layer 2 and layer 3 network topology depicted in Figure¬†4 demonstrates room for possible future contingencies. In the suggested solution, essential elements to be configured are three (3) VLANs with VLAN 10 being used for management, VLAN 20 for ACME staff access, and VLAN 100 for the point-to-point connection. The subnets assigned to these VLANs are detailed in Figure¬†4. All ports should be configured as trunk ports to allow management and staff VLANs the ability to reach ACME‚Äôs ISP in Landmark 2 directly. VLAN 100 network addresses should be assigned to an interface on the firewall in Landmark 3 and whatever device is used to manage traffic in Landmark 2. The Firewall device should be configured to manage/route VLAN traffic. If, in the future, ACME comes into an agreement with CAT to allow CAT staff to use the WLAN network then VLAN 30 can be activated and configured with the subnet provided in Figure¬†4. If this contigency is used then the Firewall device should be configured to route VLAN 30 traffic through the ACME point-to-point subnet.\n\n3.2.1 Point-To-Point Configuration\nThe antenna/base station units should be set to auto-modulate to ensure that the highest possible data rates are achieved. In addition, ensuring that the signal is transmitted on 5 Ghz band will result in the fastest, most reliable connection. As per Figure¬†6, as long as the signal received is higher than -72dBm the connection will run at the highest data rates supported by the base units. As referenced in the link budget in Figure¬†5, the transmit power should be set for 23dBm resulting in a receiving signal of -43.79dBm which is significantly higher than the minimum -72dBm needed. Finally the units should be configured to a dynamic power transmit setting so as to compensate for weather fluctuations that may interfere with the connection.\n\n\n\nFigure¬†5. Link Budget\n\n\n\n\n\nFigure¬†6. Rate to dBm\n\n\n\n\n3.2.2 Access Point Configuration\nAll access points should be configured so as not to broadcast VLAN 10‚Äôs network SSID ‚ÄúManagement‚Äù. However, it is advisable for all access points to broadcast VLAN 20‚Äôs network SSID ‚ÄúStaff‚Äù to allow easier access for users trying to connect. All access points should enable automatic channel selection and be set to transmit in both 2.4 Ghz and 5 Ghz bands. Each access point should be configured to transmit at a power of 12dBm for the 2.4Ghz band and 23dBm for the 5Ghz band as shown in Figure¬†7. Transmitting at these proposed levels will ensure all devices on premises will receive no lower than a -50dBm signal. The heat maps in @heat-maps illustrate signal strength at a -50dBm threshold. ( See Figure¬†8 )\n\n\n\nFigure¬†7. Access Point Information\n\n\n\n\n3.2.3 Heat Maps\n\n\n\n\n\n\n\n(a) 2.4 Ghz Band\n\n\n\n\n\n\n\n(b) 5 Ghz Band\n\n\n\n\nFigure¬†8. Heat maps\n\n\n\n\n3.2.4 Firewall Configuration\nA DHCP server should be configured to assign IP addresses to clients connecting to the access points. It would be recommend to enable the adblocking and website blocking features to protect the users and the network. If the VLAN 30 network is employed then the firewall should be configured to route traffic from VLAN 30 through VLAN 100 to reach services at ACME in Landmark 2. VPN features are available and may be taken advantage. Finally, it is highly recommended to enable/configure the intrusion prevension system (IPS) as this will provide an invaluable layer of security to the network.\n\n\n3.2.5 Management IP Address Distribution\nIt is suggested to assign the management devices in this solution the IP addresses shown in Figure¬†9. Figure¬†9 can easily be referenced when there is a need to access a specific device from a web browser.\n\n\n\nFigure¬†9. IP Address Subnets"
  },
  {
    "objectID": "posts/wireless-networking/wireless-networking.html#proposed-security-configuration",
    "href": "posts/wireless-networking/wireless-networking.html#proposed-security-configuration",
    "title": "Wireless Technology Networking",
    "section": "4.1 Proposed Security Configuration",
    "text": "4.1 Proposed Security Configuration\n\nUse longer more complex passwords for wireless networks\nSeparate management access from general user access by creating a management VLAN\nDon‚Äôt broadcast the SSID for the management VLAN\nEnable WPA2 and WPA3 protocols on the network and disable all other security protocols\nOnly allow the specific MAC addresses of installed access points to connect to network to deter rogue AP attacks\nConfigure the RF signal strength of access points in such a way that the network can only be reached and connected to inside the immediate premises. ( See Figure¬†6 )\nSet access points to isolate clients\nEnable automatic security updates for all devices\nEnable IPS on the firewall"
  },
  {
    "objectID": "posts/wireless-networking/wireless-networking.html#references",
    "href": "posts/wireless-networking/wireless-networking.html#references",
    "title": "Wireless Technology Networking",
    "section": "References",
    "text": "References\n\nMikroTik ‚ÄúmANTBox 52 15s\nhttps://mikrotik.com/product/mantbox_52_15s\n\n\nWC-44 Outdoor Enclosure with Clear Cover\nhttps://www.polycase.com/wc-44\n\n\nPole Mounting Assembly\nhttps://wilsonamplifiers.ca/pole-mounting-assembly-for-outdoor-antennas-10-inch-901117/\n\n\n150ft Cat8 Heavy Duty High-speed Cable\nhttps://www.amazon.ca/Ethernet-Shielded-Lastest-2000Mhz-Weatherproof/dp/B087N2BBF6\n\n\nUniFi EdgeSwitch 16XP\nhttps://store.ui.com/collections/operator-edgemax-switches/products/es-16xp\n\n\nNetgate 3100 MAX pfSense+ Security Gateway\nhttps://shop.netgate.com/products/3100-max-pfsense?variant=32156745531507\n\n\nUniFi Access Point WiFi 6 Long-Range\nhttps://store.ui.com/products/unifi-6-long-range-access-point_pos=20&_sid=883e3e553&_ss=r"
  },
  {
    "objectID": "posts/open-stack/open-stack.html#keystone-identity-service",
    "href": "posts/open-stack/open-stack.html#keystone-identity-service",
    "title": "OpenStack Virtualization",
    "section": "1.1 Keystone Identity Service",
    "text": "1.1 Keystone Identity Service\n\n\n\nFigure¬†1. Keystone - OpenRC Script"
  },
  {
    "objectID": "posts/open-stack/open-stack.html#glance-image-service",
    "href": "posts/open-stack/open-stack.html#glance-image-service",
    "title": "OpenStack Virtualization",
    "section": "1.2 Glance Image Service",
    "text": "1.2 Glance Image Service\n\n\n\nFigure¬†2. Glance - Verification Operation"
  },
  {
    "objectID": "posts/open-stack/open-stack.html#nova-compute-service",
    "href": "posts/open-stack/open-stack.html#nova-compute-service",
    "title": "OpenStack Virtualization",
    "section": "1.3 Nova Compute Service",
    "text": "1.3 Nova Compute Service\n\n\n\nFigure¬†3. Nova - Verification Operation Part 1\n\n\n\n\n\nFigure¬†4. Nova - Verification Operation Part 2"
  },
  {
    "objectID": "posts/open-stack/open-stack.html#neutron-networking-service",
    "href": "posts/open-stack/open-stack.html#neutron-networking-service",
    "title": "OpenStack Virtualization",
    "section": "1.4 Neutron Networking Service",
    "text": "1.4 Neutron Networking Service\n\n\n\nFigure¬†5. Neutron - Verification Operation"
  },
  {
    "objectID": "posts/open-stack/open-stack.html#horizon-dashboard",
    "href": "posts/open-stack/open-stack.html#horizon-dashboard",
    "title": "OpenStack Virtualization",
    "section": "1.5 Horizon Dashboard",
    "text": "1.5 Horizon Dashboard\n\n\n\nFigure¬†6. Horizon - Dashboard"
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#purpose-of-document",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#purpose-of-document",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "1.1 Purpose of Document",
    "text": "1.1 Purpose of Document\nThe purpose of this document is to provide a business case to assist ACME Inc in evaluating the viability and profitability of the proposed project. It details estimates on functions/activities, cost of development, costs of running and hardware/network requirements in developing and maintaining a machine learning software for ACME Inc."
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#scope",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#scope",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "1.2 Scope",
    "text": "1.2 Scope\nScope can be split into three parts: (1) development of machine learning software, (2) setup and deployment of data pipeline for feeding to the software and (3) maintaining the solution for sustained future company use. This proposed solution does not include training staff on machine learning software after deployment but can be negotiated."
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#background",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#background",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "2.1 Background",
    "text": "2.1 Background\nACME Inc is increasingly accumulating data on the customers that interact with the company. As the company grows, profits have not been increasing in proportion to the rising costs of larger infrastructure to support growth. At the same time marketing is struggling to identify where their efforts are most effective as the customer base widens along with product lines. The proposed project provides a solution to these problems by making use of the ever growing asset the company possesses, customer data.\n\n\n\n\n\n\nNote\n\n\n\nSee 5 Preliminary Findings of this document to investigate some of the initial insights that the prototype software has been able to uncover."
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#objectives",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#objectives",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "2.2 Objectives",
    "text": "2.2 Objectives\n2.2.1 Improve ACME‚Äôs data hygiene so that its data is better utilized.\n2.2.2 Produce new actionable insights with company data which can be used to benefit ACME.\n2.2.3 Provide concrete targets for future marketing campaigns.\n2.2.4 Increase company profits."
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#functionsactivities",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#functionsactivities",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "3.1 Functions/Activities",
    "text": "3.1 Functions/Activities\nA centralized database server will need to be securely setup for data to be loaded into for the software to access. The database server will require at least one (1) database admin to deploy and maintain. Software development itself will require three (3) phases: (1) Program, system, operations and user planning/design/documentation. (2) Development of software based on designs and deployment. (3) Maintenance of software with scheduled patches, updates and new features. To successfully execute the software development portions staff required are as follows‚Ä¶ one (1) project manager, two (2) designers, one (1) UI developer and one (2) machine learning engineers. In the maintenance stage, staff can be reduced to just one (1) manager, one (1) database admin, one (1) developer and (1) machine learning engineer."
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#cost-of-development",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#cost-of-development",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "3.2 Cost of Development",
    "text": "3.2 Cost of Development\n\n\n\n\n\n\n\n\n3.2.1\nOne (1) project manager ‚Äì 3 months\n¬£25,000\n\n\n3.2.2\nTwo (2) designers ‚Äì 1 month\n¬£10,000\n\n\n3.2.3\nOne (1) UI developer ‚Äì 1 month\n¬£5,000\n\n\n3.2.4\nOne (1) database admin ‚Äì 2 weeks\n¬£2,500\n\n\n3.2.5\nTwo (2) machine learning engineers ‚Äì 2 months\n¬£30,000\n\n\n\nTOTAL\n¬£72,500"
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#cost-of-running",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#cost-of-running",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "3.3 Cost of Running",
    "text": "3.3 Cost of Running\n\n\n\n3.3.1\nOne (1) manager ‚Äì 3 months\n¬£100,000/year\n\n\n3.3.2\nOne (1) database admin - retainer\n¬£10,000/year\n\n\n3.3.3\nOne (1) developer\n¬£60,000/year\n\n\n3.3.4\nOne (1) machine learning engineer\n¬£90,000/year\n\n\n\nTOTAL\n¬£260,000/year\n\n\n\n\n\n\n\n\n\nTotals are estimated based on current market costs as of June 2023 and are subject to change."
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#hardwarenetwork-costs",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#hardwarenetwork-costs",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "3.4 Hardware/Network Costs",
    "text": "3.4 Hardware/Network Costs\nDatabase deployment and software development can be achieved using the company‚Äôs current infrastructure and hardware available."
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#database-implementation",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#database-implementation",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "4.1 Database Implementation",
    "text": "4.1 Database Implementation\nPrototype database has been setup using a free tier Oracle Standard.A1.Flex virtual machine instance(1 CPU, 6GB RAM, Ubuntu 22.04). A MariaDB server has been installed on the instance with a user account created for the software to access the server directly. Mysql.connector and SQLAlchemy python libraries are used by the prototype software to create, delete, and access tables in the server. The prototype software allows the user to open any CSV file and to create a table on the server to import the CSV data into."
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#data-cleaning-and-exploration",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#data-cleaning-and-exploration",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "4.2 Data Cleaning and Exploration",
    "text": "4.2 Data Cleaning and Exploration\nOnce a user has selected a table using the ‚ÄúTraining Manager‚Äù toolbar, the table data is converted in a Pandas data frame for cleaning, exploration and model training. In the ‚ÄúDataFrame‚Äù toolbar the user is able to convert columns in the data frame to different data types in preparation for training. The user can also display the current data frame information and head data by using the ‚ÄúInfo‚Äù button on the ‚ÄúDataFrame‚Äù toolbar. In addition, the user can can explore the data by generating plots using the ‚ÄúDataFrame‚Äù toolbar. Finally, rows with NaN values are dropped from the data frame when the user clicks the ‚ÄúTrain Model‚Äù button so that the data fed into the algorithms doesn‚Äôt produce errors."
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#training-models",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#training-models",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "4.3 Training Models",
    "text": "4.3 Training Models\nOnce a user has selected a table using the ‚ÄúTraining Manager‚Äù toolbar, they can then select columns that they want to use to train models by using the arrow buttons. The user can select whether they want to train a linear regression, classification or clustering model using the ‚ÄúAlgorithm‚Äù combobox. If either classification or clustering options are chosen they the user can further choose the method for training whether it be: (1) KNeighbors or Decision Tree for classification, or (2) KMeans, Gaussian Mixture, or Spectral Clustering for clustering. User is able to Standardize or Normalize the data for training by making a selection using the ‚ÄúScaling‚Äù combobox. Linear regression or classification models train starting at the test size selected by the user and decrement down by 10 until a test size of 10 has finally been trained. Clustering models train classify clusters based on how many clusters are set by the ‚ÄúCluster‚Äù slider. All training results are displayed for the user in the view window."
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#predict-wine-purchases",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#predict-wine-purchases",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "5.1 Predict Wine Purchases",
    "text": "5.1 Predict Wine Purchases\nUsing a multivariate linear regression model trained on current company data the amount of wine a given customer will purchase can be predicted with 80% accuracy. This insight could be used to direct specific marketing campaigns and extend wine deals towards customers who are likely to buy more wine based on the model‚Äôs predictions. ( See Figure¬†1 )\n\n\n\nFigure¬†1. Predict Wine Purchases"
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#relationship-between-kids-wine",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#relationship-between-kids-wine",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "5.2 Relationship Between Kids & Wine",
    "text": "5.2 Relationship Between Kids & Wine\nUsing a KNeighbors classification model trained on company data it is clear to see that there is a partial relationship between the amount of wine bought and how many kids are in the home. It seems that as the amount of children in the home goes up that less wine is purchased. With this insight in mind, marketing should spend less resources advertising wine towards households that have children. ( See Figure¬†2 )\n\n\n\nFigure¬†2. Relationship Between Kids & Wine"
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#relationship-between-meats-sweets",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#relationship-between-meats-sweets",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "5.3 Relationship Between Meats & Sweets",
    "text": "5.3 Relationship Between Meats & Sweets\nUsing a KMeans clustering model trained on standardized company data, customers habits can be established between meats and sweets. As seen in Figure¬†3 customers could be placed in certain categories based on their meats and sweets purchases that would define where marketing efforts may best be spent. For example, those that buy a high amount of meats fit into a category of customer that doesn‚Äôt purchase as much sweets and visa versa. So if a customer fits into a category of high meat purchases then less efforts may be spent towards selling them sweets. ( See Figure¬†3 )\n\n\n\nFigure¬†3. Relationship Between Meats & Sweets"
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#relationship-between-gold-wine",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#relationship-between-gold-wine",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "5.4 Relationship Between Gold & Wine",
    "text": "5.4 Relationship Between Gold & Wine\nUsing a Gaussian Mixture clustering model trained on normalized company data, customers habits can be established between gold and wine. As seen in Figure¬†4 it seems that customers who purchase less gold products tend to buy more wine but not the other way around. Knowing this, marketing on wine products should not be emphasized for customers that already purchase high amounts of gold products. ( See Figure¬†4 )\n\n\n\nFigure¬†4. Relationship Between Gold & Wine"
  },
  {
    "objectID": "posts/dev-design-assignment2/design-dev-assignment2.html#software-video-walkthrough",
    "href": "posts/dev-design-assignment2/design-dev-assignment2.html#software-video-walkthrough",
    "title": "Tkinter Machine Learning Prototype Software",
    "section": "Software Video Walkthrough",
    "text": "Software Video Walkthrough\nVideo"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Brandon Toews: Artificial Intelligence BSc StudentMy projects portfolio.",
    "section": "",
    "text": "Deep Learning FastAI Model\n\n\n\n\n\n\n\nai\n\n\ndeep learning\n\n\nneural network\n\n\nfastai\n\n\nkaggle\n\n\ncolab\n\n\nvision\n\n\nhyperparameter\n\n\noptimization\n\n\n\n\nProject to train a deep learning model to correctly classify an image of a wasp or a bee using transfer learning with the fastai library.\n\n\n\n\n\n\nJun 9, 2023\n\n\nBrandon Toews\n\n\n\n\n\n\n  \n\n\n\n\nTkinter Machine Learning Prototype Software\n\n\n\n\n\n\n\ndesign\n\n\ndevelopment\n\n\nai\n\n\nmachine learning\n\n\ntkinter\n\n\nui\n\n\ndatabase\n\n\n\n\nProject to design and develop a prototype software with UI to import, transform and save data to and from a cloud database. Software built to apply machine learning algorithms to explore interesting findings from dataset and use to propose a business case for the design.\n\n\n\n\n\n\nJun 5, 2023\n\n\nBrandon Toews\n\n\n\n\n\n\n  \n\n\n\n\nProgramming Design Patterns\n\n\n\n\n\n\n\nalgorithms\n\n\nc++\n\n\ngames\n\n\nunreal\n\n\nprogramming\n\n\npatterns\n\n\nai\n\n\n\n\nMechanics sandbox game to demonstrate programming design patterns using Unreal Engine. Implemented command, state machine, object pool & prototype design patterns using C++ and Unreal‚Äôs Blueprints Visual Scripting system.\n\n\n\n\n\n\nMay 19, 2023\n\n\nBrandon Toews\n\n\n\n\n\n\n  \n\n\n\n\nStar Map Navigation Simulation\n\n\n\n\n\n\n\nmathematics\n\n\nc#\n\n\ngames\n\n\nunity\n\n\ndjikstra\n\n\nai\n\n\nmatrices\n\n\n\n\nUnity Games Engine project to implement a star map navigation style simulation with custom pathfinding script.\n\n\n\n\n\n\nMay 13, 2023\n\n\nBrandon Toews\n\n\n\n\n\n\n  \n\n\n\n\nRetro C++ Game LaserMan\n\n\n\n\n\n\n\nalgorithms\n\n\nc++\n\n\ngames\n\n\nprogramming\n\n\nplaybuffer\n\n\n\n\nRetro game written in C++ using a beginner‚Äôs game-development framework called Playbuffer\n\n\n\n\n\n\nJan 13, 2023\n\n\nBrandon Toews\n\n\n\n\n\n\n  \n\n\n\n\nLinear Regression, Classification, Clustering\n\n\n\n\n\n\n\nai\n\n\nlinear regression\n\n\nclassification\n\n\nclustering\n\n\nmachine learning\n\n\n\n\nProject to compare different AI algorithms and an exploration of how to improve their accuracy.\n\n\n\n\n\n\nDec 22, 2022\n\n\nBrandon Toews\n\n\n\n\n\n\n  \n\n\n\n\nHotel Booking System Mock Design\n\n\n\n\n\n\n\ndesign\n\n\ndevelopment\n\n\nmethodologies\n\n\nentity-relationship diagram\n\n\ncontext diagram\n\n\ndata flow diagram\n\n\n\n\nProject to design a hotel booking system based on a mock system design case scenario.\n\n\n\n\n\n\nDec 9, 2022\n\n\nBrandon Toews\n\n\n\n\n\n\n  \n\n\n\n\nModes of Motion Programming Mathematics\n\n\n\n\n\n\n\nmathematics\n\n\nc#\n\n\ngames\n\n\nunity\n\n\nlerp\n\n\n\n\nUnity Games Engine project to demonstrate various methods of movement, making use of custom linear interpolation (lerp) libraries and scripts using Unity physics.\n\n\n\n\n\n\nNov 30, 2022\n\n\nBrandon Toews\n\n\n\n\n\n\n  \n\n\n\n\nAutomation in Systems Administration Project\n\n\n\n\n\n\n\nnetworking\n\n\ndesign\n\n\nmicrosoft\n\n\nnetwork diagram\n\n\n\n\nProject to plan and design an expansion to a fictitious Microsoft Windows Server based network, develop a prototype network, and to produce documentation along with it.\n\n\n\n\n\n\nSep 19, 2022\n\n\nBrandon Toews\n\n\n\n\n\n\n  \n\n\n\n\nLinux Administration Project\n\n\n\n\n\n\n\nnetworking\n\n\ndesign\n\n\nlinux\n\n\nldap\n\n\nnetwork diagram\n\n\n\n\nProject to design and setup a mock prototype network using headless CentOS 7.0 servers and to produce documentation along with it.\n\n\n\n\n\n\nJun 17, 2022\n\n\nBrandon Toews\n\n\n\n\n\n\n  \n\n\n\n\nOpenStack Virtualization\n\n\n\n\n\n\n\nnetworking\n\n\nopenstack\n\n\nvirtualization\n\n\ncloud computing\n\n\n\n\nCreated an OpenStack environment by manually installing and configuring services.\n\n\n\n\n\n\nMar 17, 2022\n\n\nBrandon Toews\n\n\n\n\n\n\n  \n\n\n\n\nMicrosoft Exchange Server Network\n\n\n\n\n\n\n\nnetworking\n\n\nmicrosoft\n\n\nexchange server\n\n\nactive directory\n\n\n\n\nDeployed an Exchange server environment using Microsoft Exchange Server 2016.\n\n\n\n\n\n\nMar 3, 2022\n\n\nBrandon Toews\n\n\n\n\n\n\n  \n\n\n\n\nWireless Technology Networking\n\n\n\n\n\n\n\nnetworking\n\n\nwireless\n\n\nwlan\n\n\n\n\nDesigned a mock solution for a P2P network with wifi coverage. Produced documentation to propose hardware, along with instructions for installation and configuration.\n\n\n\n\n\n\nDec 19, 2021\n\n\nBrandon Toews\n\n\n\n\n\n\n  \n\n\n\n\nNetworking with Cisco Technologies\n\n\n\n\n\n\n\nnetworking\n\n\ncisco\n\n\nvmware\n\n\nnetwork diagram\n\n\nrouting\n\n\n\n\nDesigned and constructed a fictional network using GNS3 simulation software and VMs running on VMware.\n\n\n\n\n\n\nDec 14, 2021\n\n\nBrandon Toews\n\n\n\n\n\n\nNo matching items"
  }
]